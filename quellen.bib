
@article{gondwe_can_2025,
	title = {Can {AI} {Outsmart} {Fake} {News}? {Detecting} {Misinformation} {With} {AI} {Models} in {Real}-{Time}},
	issn = {2752-3543, 2752-3551},
	shorttitle = {Can {AI} {Outsmart} {Fake} {News}?},
	url = {https://journals.sagepub.com/doi/10.1177/27523543251325902},
	doi = {10.1177/27523543251325902},
	abstract = {This study employed a hybrid methodological approach that integrated machine learning, natural language processing, and deep learning to evaluate AI algorithms for real-time misinformation detection. Using a dataset of 10,000 entries balanced across true, false, and uncertain claims, models were trained and tested on accuracy, precision, recall, F1-score, and receiver operating characteristic area under the curve metrics. Real-time capabilities were assessed on 5,000 live social media posts collected during the Trump versus Harris debate. This allowed for a critical evaluation of the models in real-world settings. Data were sourced from reputable news outlets, misinformation sites, and social media platforms, employing relevant hashtags and keywords related to misinformation narratives. The results show that transformer-based models, particularly bidirectional encoder representations from transformer (BERT) and generative pretrained transformer, outperformed traditional machine learning models like support vector machines, Naive Bayes, and Random Forest, demonstrating superior accuracy, precision, and contextual understanding. BERT achieved the highest performance with an accuracy of 94.8\% and a precision of 93.5\%. However, the computational demands of these models posed significant challenges for real-time deployment, thus, highlighting the need for optimization strategies such as hyperparameter tuning and model compression. The study also addressed ethical concerns, using adversarial testing and interpretability tools like local interpretable model-agnostic explanations to ensure fairness and transparency. Models trained on fact-checked datasets outperformed those trained on unverified social media data, underscoring the impact of training data quality on model performance.},
	language = {en},
	urldate = {2025-05-03},
	journal = {Emerging Media},
	author = {Gondwe, Gregory},
	month = mar,
	year = {2025},
	pages = {27523543251325902},
}

@article{santos_artificial_2023,
	title = {Artificial {Intelligence} in {Automated} {Detection} of {Disinformation}: {A} {Thematic} {Analysis}},
	volume = {4},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2673-5172},
	shorttitle = {Artificial {Intelligence} in {Automated} {Detection} of {Disinformation}},
	url = {https://www.mdpi.com/2673-5172/4/2/43},
	doi = {10.3390/journalmedia4020043},
	abstract = {The increasing prevalence of disinformation has led to a growing interest in leveraging artificial intelligence (AI) for detecting and combating this phenomenon. This article presents a thematic analysis of the potential benefits of automated disinformation detection from the perspective of information sciences. The analysis covers a range of approaches, including fact checking, linguistic analysis, sentiment analysis, and the utilization of human-in-the-loop systems. Furthermore, the article explores how the combination of blockchain and AI technologies can be used to automate the process of disinformation detection. Ultimately, the article aims to consider the integration of AI into journalism and emphasizes the importance of ongoing collaboration between these fields to effectively combat the spread of disinformation. The article also addresses ethical considerations related to the use of AI in journalism, including concerns about privacy, transparency, and accountability.},
	language = {en},
	number = {2},
	urldate = {2025-05-03},
	journal = {Journalism and Media},
	author = {Santos, Fátima C. Carrilho},
	month = jun,
	year = {2023},
	pages = {679--687},
}

@article{lu_effects_2022,
	title = {The {Effects} of {AI}-based {Credibility} {Indicators} on the {Detection} and {Spread} of {Misinformation} under {Social} {Influence}},
	volume = {6},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3555562},
	doi = {10.1145/3555562},
	abstract = {Misinformation on social media has become a serious concern. Marking news stories with credibility indicators, possibly generated by an AI model, is one way to help people combat misinformation. In this paper, we report the results of two randomized experiments that aim to understand the effects of AI-based credibility indicators on people's perceptions of and engagement with the news, when people are under social influence such that their judgement of the news is influenced by other people. We find that the presence of AI-based credibility indicators nudges people into aligning their belief in the veracity of news with the AI model's prediction regardless of its correctness, thereby changing people's accuracy in detecting misinformation. However, AI-based credibility indicators show limited impacts on influencing people's engagement with either real news or fake news when social influence exists. Finally, it is shown that when social influence is present, the effects of AI-based credibility indicators on the detection and spread of misinformation are larger as compared to when social influence is absent, when these indicators are provided to people before they form their own judgements about the news. We conclude by providing implications for better utilizing AI to fight misinformation.},
	language = {en},
	number = {CSCW2},
	urldate = {2025-05-03},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lu, Zhuoran and Li, Patrick and Wang, Weilong and Yin, Ming},
	month = nov,
	year = {2022},
	pages = {1--27},
}

@inproceedings{qin_timing_2025,
	address = {Yokohama Japan},
	title = {Timing {Matters}: {How} {Using} {LLMs} at {Different} {Timings} {Influences} {Writers}' {Perceptions} and {Ideation} {Outcomes} in {AI}-{Assisted} {Ideation}},
	isbn = {979-8-4007-1394-1},
	shorttitle = {Timing {Matters}},
	url = {https://dl.acm.org/doi/10.1145/3706598.3713146},
	doi = {10.1145/3706598.3713146},
	language = {en},
	urldate = {2025-05-03},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Qin, Peinuan and Yang, Chi-Lan and Li, Jingshu and Wen, Jing and Lee, Yi-Chieh},
	month = apr,
	year = {2025},
	pages = {1--16},
}

@article{braun_using_2006,
	title = {Using thematic analysis in psychology},
	volume = {3},
	doi = {10.1191/1478088706qp063oa},
	journal = {Qualitative Research in Psychology},
	author = {Braun, Virginia and Clarke, Victoria},
	month = jan,
	year = {2006},
	pages = {77--101},
}

@inproceedings{laugwitz_construction_2008,
	address = {Berlin, Heidelberg},
	title = {Construction and {Evaluation} of a {User} {Experience} {Questionnaire}},
	isbn = {978-3-540-89350-9},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practical relevance of items. Usability experts collected terms and statements on user experience and usability, including `hard' as well as `soft' aspects. These statements were consolidated and transformed into a first questionnaire version containing 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six factors Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and Novelty. Studies conducted for the original German questionnaire and an English version indicate a satisfactory level of reliability and construct validity.},
	booktitle = {{HCI} and {Usability} for {Education} and {Work}},
	publisher = {Springer Berlin Heidelberg},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	editor = {Holzinger, Andreas},
	year = {2008},
	pages = {63--76},
}

@inproceedings{ev_dlr-wat_2018,
	title = {{DLR}-{WAT}: {Ein} {Instrument} zur {Untersuchung} des optimalen {Beanspruchungsniveaus} in hochautomatisierten {Mensch}-{Maschine}-{Systemen}},
	url = {https://elib.dlr.de/119443/},
	abstract = {In diesem Artikel wird das "`DLR - Workload Assessment Tool"' (DLR–WAT) vorgestellt, ein Fragebogen zur Selbsteinschätzung der Beanspruchung, der gezielter als bestehende Messwerkzeuge wie z.B. der NASA-TLX Abweichungen von einem subjektiven Optimum der Beanspruchung berücksichtigt. Automatisierung und Digitalisierung sind derzeit die bestimmenden Trends im Personen- und Güterverkehr. Ob auf der Straße, der Schiene oder in der Luft, die Rolle des Menschen im Verkehr wandelt sich im Angesicht dieser Entwicklungen rapide. Technische Assistenzen unterstützen den Menschen und hochautomatisierte Systeme übernehmen in einzelnen Bereichen bereits Aufgaben des Menschen wie z.B. die Steuerung und Navigation. Die aktive Rolle des Menschen, zum Beispiel in der Rolle des Fahrers, wandelt sich sukzessive hin zu einer passiveren Rolle, die durch kontinuierliches Überwachen geprägt ist. Generell kann der Mensch durch Automation entlastet und sein Komfort gesteigert werden. Die Anforderung an den Menschen, seine Aufmerksamkeit konsequent aufrecht zu erhalten, auch wenn er nicht handeln muss, um in unsicheren oder kritischen Situationen kurzfristig in der Lage zu sein, die Steuerung zu übernehmen, stellt allerdings eine Schattenseite des Automationskomforts dar. Unter der Berücksichtigung der zunehmend passiven Rolle des Menschen in hochautomatisierten Verkehrssystemen, gewinnt das Thema der Unterbeanspruchung mit wachsender Automatisierung an Bedeutung. Erhebungsinstrumente zur subjektiven Einschätzung der eigenen Beanspruch differenzieren bislang jedoch nicht klar zwischen einem Unterforderungs- und einem Überforderungsbereich. Vor diesem Hintergrund wurde der DLR-WAT entwickelt. Der DLR–WAT umfasst insgesamt acht Subskalen. Auf sechs der acht Subskalen (Beanspruchung durch Informationsaufnahme, Beanspruchung durch Wissensabruf, Beanspruchung durch Entscheidungsfindung, motorische und körperliche Beanspruchung, zeitliche Beanspruchung und Anstrengung) kann der Befragte seinen Beanspruchungszustand angeben, ausgehend von seinem persönlichen Optimum, das in der Mitte jeder Subskala verortet ist. Die zwei weiteren Subskalen des DLR-WAT (Frustration, Aufgabenbewältigung) sind eindimensional gestaltet, da ein optimales Frustrationsniveau durch Abwesenheit der Frustration gekennzeichnet ist und es nicht möglich ist, eine Aufgabe weniger als gar nicht zu bewältigen. Die Berücksichtigung des persönlichen Optimums der Beanspruchung im DLR–WAT in den ersten sechs Subskalen ermöglicht im Zuge der Entwicklung hochautomatisierter Verkehrssysteme eine detailliertere Beanspruchungsanalyse als bestehende Fragebögen. Dies eröffnet in der Gestaltung zukünftiger interaktiver Verkehrssysteme die Chance, den schmalen Grat zwischen Überforderung und Unterforderung zielgerichtet zu identifizieren und Aufgaben zwischen Mensch und Automation entsprechend zu verteilen.},
	booktitle = {{AAET} {Automatisiertes} \& {Vernetztes} {Fahren}},
	author = {Grippenkoven, Jan and Rodd, Justin and Brandenburger, Niels},
	editor = {e.V, ITS mobility},
	month = mar,
	year = {2018},
	keywords = {Automation, Beanspruchung, DLR-WAT, Fragebogen, Human Factors, Workload},
	pages = {199--213},
}

@inproceedings{madsen_measuring_2000,
	title = {Measuring {Human}-{Computer} {Trust}},
	url = {https://api.semanticscholar.org/CorpusID:18821611},
	author = {Madsen, Maria and Gregor, Shirley D.},
	year = {2000},
}
