
@inproceedings{qin_timing_2025,
	address = {Yokohama Japan},
	title = {Timing {Matters}: {How} {Using} {LLMs} at {Different} {Timings} {Influences} {Writers}' {Perceptions} and {Ideation} {Outcomes} in {AI}-{Assisted} {Ideation}},
	isbn = {979-8-4007-1394-1},
	shorttitle = {Timing {Matters}},
	url = {https://dl.acm.org/doi/10.1145/3706598.3713146},
	doi = {10.1145/3706598.3713146},
	language = {en},
	urldate = {2025-04-29},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Qin, Peinuan and Yang, Chi-Lan and Li, Jingshu and Wen, Jing and Lee, Yi-Chieh},
	month = apr,
	year = {2025},
	pages = {1--16},
}

@article{moon_fact-checking_2025,
	title = {Fact-checking in the age of {AI}: {Reducing} biases with non-human information sources},
	volume = {80},
	issn = {0160-791X},
	url = {https://www.sciencedirect.com/science/article/pii/S0160791X24003087},
	doi = {https://doi.org/10.1016/j.techsoc.2024.102760},
	abstract = {This study examines the obstacles to the effectiveness of fact-checking, focusing primarily on the pervasive impact of entrenched biases. Fact-checking efforts often face resistance when linked to mistrusted sources, leading to cognitive dissonance and the rejection of messages in favor of pre-existing beliefs, a phenomenon known as motivated reasoning. This resistance hinders organizationsâ€™ ability to correct misconceptions surrounding social issues and entities. The research delves into whether non-human entities such as AI can facilitate less biased information processing due to their perceived impartiality. Applying a moderated mediation model in experimental settings, we found that labeling a source as artificial intelligence is pivotal in evaluating fact-checking. AI labels moderate the impact of partisan biases on the persuasive outcomes of fact-checks, such as message credibility and acceptance, compared to the human source. This study offers valuable insights for enhancing the effectiveness of fact-checking in the context of cognitive and psychological biases by highlighting the critical influence of information sources in reducing polarization in public perceptions of scientific issues.},
	journal = {Technology in Society},
	author = {Moon, Won-Ki and Kahlor, Lee Ann},
	year = {2025},
	keywords = {AI, Bias, Fact checking, Human-AI interaction, Information processing, Misinformation, Motivated reasoning},
	pages = {102760},
}

@article{lu_effects_2022,
	title = {The {Effects} of {AI}-based {Credibility} {Indicators} on the {Detection} and {Spread} of {Misinformation} under {Social} {Influence}},
	volume = {6},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3555562},
	doi = {10.1145/3555562},
	abstract = {Misinformation on social media has become a serious concern. Marking news stories with credibility indicators, possibly generated by an AI model, is one way to help people combat misinformation. In this paper, we report the results of two randomized experiments that aim to understand the effects of AI-based credibility indicators on people's perceptions of and engagement with the news, when people are under social influence such that their judgement of the news is influenced by other people. We find that the presence of AI-based credibility indicators nudges people into aligning their belief in the veracity of news with the AI model's prediction regardless of its correctness, thereby changing people's accuracy in detecting misinformation. However, AI-based credibility indicators show limited impacts on influencing people's engagement with either real news or fake news when social influence exists. Finally, it is shown that when social influence is present, the effects of AI-based credibility indicators on the detection and spread of misinformation are larger as compared to when social influence is absent, when these indicators are provided to people before they form their own judgements about the news. We conclude by providing implications for better utilizing AI to fight misinformation.},
	language = {en},
	number = {CSCW2},
	urldate = {2025-04-29},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lu, Zhuoran and Li, Patrick and Wang, Weilong and Yin, Ming},
	month = nov,
	year = {2022},
	pages = {1--27},
}
