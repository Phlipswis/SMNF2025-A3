
@article{gondwe_can_2025,
	title = {Can {AI} {Outsmart} {Fake} {News}? {Detecting} {Misinformation} {With} {AI} {Models} in {Real}-{Time}},
	issn = {2752-3543, 2752-3551},
	shorttitle = {Can {AI} {Outsmart} {Fake} {News}?},
	url = {https://journals.sagepub.com/doi/10.1177/27523543251325902},
	doi = {10.1177/27523543251325902},
	abstract = {This study employed a hybrid methodological approach that integrated machine learning, natural language processing, and deep learning to evaluate AI algorithms for real-time misinformation detection. Using a dataset of 10,000 entries balanced across true, false, and uncertain claims, models were trained and tested on accuracy, precision, recall, F1-score, and receiver operating characteristic area under the curve metrics. Real-time capabilities were assessed on 5,000 live social media posts collected during the Trump versus Harris debate. This allowed for a critical evaluation of the models in real-world settings. Data were sourced from reputable news outlets, misinformation sites, and social media platforms, employing relevant hashtags and keywords related to misinformation narratives. The results show that transformer-based models, particularly bidirectional encoder representations from transformer (BERT) and generative pretrained transformer, outperformed traditional machine learning models like support vector machines, Naive Bayes, and Random Forest, demonstrating superior accuracy, precision, and contextual understanding. BERT achieved the highest performance with an accuracy of 94.8\% and a precision of 93.5\%. However, the computational demands of these models posed significant challenges for real-time deployment, thus, highlighting the need for optimization strategies such as hyperparameter tuning and model compression. The study also addressed ethical concerns, using adversarial testing and interpretability tools like local interpretable model-agnostic explanations to ensure fairness and transparency. Models trained on fact-checked datasets outperformed those trained on unverified social media data, underscoring the impact of training data quality on model performance.},
	language = {en},
	urldate = {2025-05-03},
	journal = {Emerging Media},
	author = {Gondwe, Gregory},
	month = mar,
	year = {2025},
	pages = {27523543251325902},
}

@article{santos_artificial_2023,
	title = {Artificial {Intelligence} in {Automated} {Detection} of {Disinformation}: {A} {Thematic} {Analysis}},
	volume = {4},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2673-5172},
	shorttitle = {Artificial {Intelligence} in {Automated} {Detection} of {Disinformation}},
	url = {https://www.mdpi.com/2673-5172/4/2/43},
	doi = {10.3390/journalmedia4020043},
	abstract = {The increasing prevalence of disinformation has led to a growing interest in leveraging artificial intelligence (AI) for detecting and combating this phenomenon. This article presents a thematic analysis of the potential benefits of automated disinformation detection from the perspective of information sciences. The analysis covers a range of approaches, including fact checking, linguistic analysis, sentiment analysis, and the utilization of human-in-the-loop systems. Furthermore, the article explores how the combination of blockchain and AI technologies can be used to automate the process of disinformation detection. Ultimately, the article aims to consider the integration of AI into journalism and emphasizes the importance of ongoing collaboration between these fields to effectively combat the spread of disinformation. The article also addresses ethical considerations related to the use of AI in journalism, including concerns about privacy, transparency, and accountability.},
	language = {en},
	number = {2},
	urldate = {2025-05-03},
	journal = {Journalism and Media},
	author = {Santos, FÃ¡tima C. Carrilho},
	month = jun,
	year = {2023},
	pages = {679--687},
	file = {Volltext:C\:\\Users\\phili\\Zotero\\storage\\ZBWJFWEE\\Santos - 2023 - Artificial Intelligence in Automated Detection of Disinformation A Thematic Analysis.pdf:application/pdf},
}

@article{lu_effects_2022,
	title = {The {Effects} of {AI}-based {Credibility} {Indicators} on the {Detection} and {Spread} of {Misinformation} under {Social} {Influence}},
	volume = {6},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3555562},
	doi = {10.1145/3555562},
	abstract = {Misinformation on social media has become a serious concern. Marking news stories with credibility indicators, possibly generated by an AI model, is one way to help people combat misinformation. In this paper, we report the results of two randomized experiments that aim to understand the effects of AI-based credibility indicators on people's perceptions of and engagement with the news, when people are under social influence such that their judgement of the news is influenced by other people. We find that the presence of AI-based credibility indicators nudges people into aligning their belief in the veracity of news with the AI model's prediction regardless of its correctness, thereby changing people's accuracy in detecting misinformation. However, AI-based credibility indicators show limited impacts on influencing people's engagement with either real news or fake news when social influence exists. Finally, it is shown that when social influence is present, the effects of AI-based credibility indicators on the detection and spread of misinformation are larger as compared to when social influence is absent, when these indicators are provided to people before they form their own judgements about the news. We conclude by providing implications for better utilizing AI to fight misinformation.},
	language = {en},
	number = {CSCW2},
	urldate = {2025-05-03},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lu, Zhuoran and Li, Patrick and Wang, Weilong and Yin, Ming},
	month = nov,
	year = {2022},
	pages = {1--27},
}

@inproceedings{qin_timing_2025,
	address = {Yokohama Japan},
	title = {Timing {Matters}: {How} {Using} {LLMs} at {Different} {Timings} {Influences} {Writers}' {Perceptions} and {Ideation} {Outcomes} in {AI}-{Assisted} {Ideation}},
	isbn = {979-8-4007-1394-1},
	shorttitle = {Timing {Matters}},
	url = {https://dl.acm.org/doi/10.1145/3706598.3713146},
	doi = {10.1145/3706598.3713146},
	language = {en},
	urldate = {2025-05-03},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Qin, Peinuan and Yang, Chi-Lan and Li, Jingshu and Wen, Jing and Lee, Yi-Chieh},
	month = apr,
	year = {2025},
	pages = {1--16},
	file = {Eingereichte Version:C\:\\Users\\phili\\Zotero\\storage\\YEKWI8EA\\Qin et al. - 2025 - Timing Matters How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Out.pdf:application/pdf},
}
