---
title: "Zwischen Vertrauen und Überforderung: KI als Werkzeug gegen Misinformation?"
date: today

author:
  - Tara Dethlefsen
  - Jonas Joost
  - Vivien Ramhold
  - Niklas von der Fecht
  - Philipp Wisser

lang: de

format:
  html: default
  pdf:
    papersize: a4
    fontsize: 12pt
    number-sections: true
    
bibliography: quellen.bib
csl: apa.csl

editor: visual
---

```{r setup}
#| echo: false
suppressPackageStartupMessages({
  library(kableExtra)
  library(dplyr)
  library(psych)
  library(ggplot2)
  library(tidyr)
})

data_combined <- read.csv("Daten/data_combined.csv")
web_app_data <- read.csv("Daten/web_app_data.csv")

web_app_filtered <- web_app_data %>%
  filter(system %in% c("E", "R"))
web_app_unique <- web_app_filtered %>%
  group_by(participantId) %>%
  summarise(system = first(system), .groups = "drop")
data_complete <- merge(data_combined, web_app_unique, by = "participantId", all.x = TRUE)
```

**Github Repository und Commit-Hash**

-   **Repository:** \[https://github.com/Phlipswis/SMNF2025-A3\]

```{r}
#| echo: false
gitHash = system("git rev-parse HEAD", intern = TRUE)
```

-   **Commit-Hash:** `{r} gitHash`\

**Code of Conduct**

Mit dem Folgenden formulieren wir gemeinsame Regeln und Grundsätze, die unser Miteinander und unsere Arbeitsweise leiten.

Ein zentraler Aspekt ist der respektvolle Umgang mit Feedback sowie unterschiedlichen Perspektiven und Meinungen. Deshalb formulieren wir Kritik konstruktiv mit dem Ziel, gemeinsam eine Lösung zu finden. Die Aufteilung der Arbeitslast erfolgt in unserer Gruppe fair und unter Berücksichtigung der individuellen Fähigkeiten. Jedes Gruppenmitglied übernimmt Verantwortung für seine Aufgaben und trägt so aktiv zum Gelingen des Gesamtprojekts bei. Vereinbarte Termine betrachten wir als verbindlich. Sollte ein Termin aus nachvollziehbaren Gründen nicht eingehalten werden können, informieren wir die Gruppe frühzeitig, damit gemeinsam alternative Lösungen gefunden werden können.

Wir verpflichten uns ehrlich, sorgfältig und transparent zu arbeiten. Plagiate, Datenmanipulation und andere Formen wissenschaftlichen Fehlverhaltens lehnen wir ab. Alle verwendeten Quellen werden ordnungsgemäß zitiert und die Ergebnisse unserer Arbeit werden stets nachvollziehbar dokumentiert.

Zum Schutz der personenbezogenen und sensiblen Daten gehen wir verantwortungsvoll mit den Informationen um, die uns anvertraut werden. Dabei halten wir uns an die geltenden Datenschutzrichtlinien und sorgen dafür, dass Daten nur für die vorgesehenen Zwecke verwendet und vor unbefugtem Zugriff geschützt werden.

Die Nutzung von Künstlicher Intelligenz (KI) beschränkt sich auf die Korrektur von Rechtschreibung und Grammatik sowie das Generieren von R- und Quarto-Code. In allen anderen Fällen wird die Nutzung von KI-Tools gemäß der Richtlinien der American Psychological Association in der 7. Auflage kenntlich gemacht.

# Einleitung

Ein Übersichtsartikel von Aïmeur et al. [-@aimeur_fake_2023] zeigt, dass Social Media für immer mehr Nutzende zu einer zentralen Informationsquelle wird. Bekannte Plattformen wie Instagram oder X werden dabei nicht mehr nur zur privaten Kommunikation genutzt, sondern dienen zunehmend als Ersatz für traditionelle Nachrichtendienste. Aufgrund der nahezu uneingeschränkten Möglichkeit, Inhalte frei und ohne redaktionelle Kontrolle zu veröffentlichen, sind auf Social Media jedoch viele Misinformationen zu finden. Die Detektion solcher Inhalte ist besonders vor dem Hintergrund potentieller gesellschaftlicher und politischer Auswirkungen von Bedeutung. Eine manuelle Identifikation ist angesichts der Menge und schnellen Verbreitung kaum umsetzbar. Daher wird verstärkt auf den Einsatz von KI gesetzt, um Misinformation zu erkennen und die Verbreitung einzudämmen.

Santos [-@santos_artificial_2023] zeigt, dass KI das Potenzial besitzt, Nutzende als Werkzeug wirksam bei der Identifikation von Misinformation zu unterstützen. Künstliche Intelligenz ist jedoch ein dynamisches und junges Technologiefeld, welches kontinuierlichem Wandel unterliegt. Daher ist bislang unklar, wie diese Technologien konkret und nachhaltig in reale Anwendungskontexte integriert werden können. Besonders im Bereich der Mensch-Computer-Interaktion im Kontext der Detektion von Misinformation mangelt es bislang an konkreten empirischen Erkenntnissen.

Aus dem gegebenen Anlass verfolgen wir in unserer Studie das Ziel Antworten auf folgende vier Forschungsfragen zu finden. Unsere primäre Forschungsfrage lautet: _Erleichtert der Einsatz von KI als Werkzeug die Detektion von Misinformation auf Social Media?_ Hierbei ist unser Ziel festzustellen, ob KI aus Sicht der Nutzenden tatsächlich eine effektive Unterstützung ist. Mit unserer zweiten Forschungsfrage wollen wir beantworten, was die Nutzenden von einer KI fordern, um sie effektiv als Detektionstool nutzen zu können. Konkret lautet sie: _Was sind die Nutzungsanforderungen an KI als Werkzeug zur Unterstützung bei der Detektion von Misinformation?_ Darüber hinaus untersuchen wir ebenfalls, wie sich die Nutzung von verschiedenen KI-Typen auf den Nutzenden auswirkt: _Wie unterscheidet sich die User-Experience bei der Nutzung von einer empfehlenden KI im Vergleich zu einer evaluativen KI bei der Detektion von Misinformation auf Social Media?_ Zuletzt gehen wir der Frage nach, ob das Alter in Abhängigkeit zum Vertrauen in die Anwendung steht. Dies tun wir mittels der Fragenstellung: _Wie beeinflusst das Alter der Nutzenden ihr Vertrauen in KI-Systeme als Unterstützung bei der Detektion von Misinformation auf Social Media?_

Unsere Studie umfasst sowohl einen qualitativen als auch einen quantitativen Forschungsansatz. In diesem Extended Abstract sind im Abschnitt „Methodik“ sowie „Ergebnisse“ jeweils separate Unterabschnitte für die beiden Studienteile enthalten. Die abschließende Diskussion bezieht sich auf die Erkenntnisse beider Methodenteile und stellt diese gegenüber.

# Literaturübersicht

Die thematische Analyse aktueller Forschung von Santos [-@santos_artificial_2023] zeigt, dass der Einsatz von KI-Technologien eine vielversprechende Methode zur Identifikation von Misinformationen auf Social Media darstellt. Er hebt hervor, dass KI vor allem durch die Fähigkeit überzeugt, große Datenmengen systematisch zu analysieren und Misinformationen effizienter als manuelle Verfahren zu identifizieren. Diese technische Überlegenheit bestätigt auch Gondwe [-@gondwe_can_2025] in seiner Studie. Er betont, dass moderne KI-Modelle klassischen Modellen in ihrer Genauigkeit bei der Detektion von Misinformationen überlegen sind. Gleichzeitig weist Gondwe jedoch auf die Bedeutung vielfältiger und kontinuierlich aktualisierter Trainingsdaten hin, um Verzerrungen und Fehlinterpretationen zu vermeiden.

Neben der technologischen Perspektive bietet die Forschung von Moon et al. [-@moon_fact-checking_2025] wichtige Einblicke in die Nutzerwahrnehmung. Ihre empirischen Ergebnisse zeigen, dass KI-basierte Faktenprüfungen tendenziell als weniger parteiisch wahrgenommen werden als menschliche Bewertungen. Dies ist insbesondere bei politisch sensiblen Themen von Bedeutung. Die Kennzeichnung einer KI-Überprüfung steigert dabei die Glaubwürdigkeit der Faktenchecks.

Ein weiterer relevanter Aspekt ist die Rolle von individuellen und kulturellen Faktoren im Vertrauen gegenüber KI-Systemen. Montag et al. [-@montag_trust_2024] betonen, dass das Vertrauen in KI alters- und kulturspezifisch variiert. Das Alter wird in ihrer Analyse jedoch nur als Kovariante berücksichtigt und somit nicht genauer betrachtet. Die vermutete altersbezogene Relevanz wird jedoch durch Ahmed et al. [-@ahmed_social_2023] gestützt. Sie zeigen, dass das Alter einen wesentlichen Einfluss auf digitales Verhalten und die Reaktion auf Misinformationen hat. Während jüngere Nutzende aktiver in digitalen Räumen agieren, sind ältere Personen empfänglicher für wahrgenommene Misinformationen.

Die analysierte Literatur verdeutlicht, dass KI-Systeme großes Potenzial in der Bekämpfung von Misinformation auf Social Media bieten. Dennoch bleiben zentrale Fragen hinsichtlich der Nutzererfahrung, den Nutzungsanforderungen und dem Einfluss individueller Faktoren wie dem Alter bislang offen. Diese Aspekte stehen im Fokus unserer Studie.

# Methode

## Qualitative Methode

Im ersten Teil unserer Studie entschieden wir uns für einen qualitativen Forschungsansatz, um individuelle Erfahrungen und Sichtweisen der Teilnehmenden zu erfassen. Im Mittelpunkt stand die Frage, welche Nutzungsanforderungen an KI als Werkzeug zur Unterstützung bei der Detektion von Misinformation auf Social Media bestehen. Darüber hinaus untersuchten wir, inwieweit die Teilnehmenden den Einsatz von KI als Erleichterung bei der Identifikation von Misinformation wahrnehmen.

Zur Datenerhebung führten wir jeweils ein leitfadengestütztes Interview mit mehreren Teilnehmenden durch. Die Rekrutierung der Teilnehmenden erfolgte gezielt durch persönliche Ansprache. Dabei achteten wir darauf, dass sie über grundlegende Kenntnisse im Umgang mit KI verfügten. Die Interviews wurden entweder online mit Aufzeichnung über OBS-Studio durchgeführt oder vor Ort unter Verwendung eines Diktiergeräts. Vor Beginn der Interviews unterzeichneten alle Teilnehmenden eine Einwilligungserklärung mit Informationen zur Studie, Datenschutz und anonymisierter Auswertung. Die Gespräche wurden anschließend mit der Transkriptionssoftware Whisper verschriftlicht, folgend händisch überarbeitet und anonymisiert.

Für die Analyse verwendeten wir die Thematische Analyse nach Braun und Clarke [-@braun_using_2006]. Ziel war es, aus dem Material übergeordnete Themen zu extrahieren, die zentrale Anforderungen der Nutzenden widerspiegeln. Die Analyse wurde manuell in Microsoft Word durchgeführt und erfolgte induktiv. Zunächst analysierten wir die Transkripte unabhängig voneinander. Anschließend wurden die identifizierten Codes und Themen im Abgleich zusammengeführt. Bei abweichenden Codierungen wurden die Unterschiede besprochen und schließlich zu einer validen und konsistenten Kategorisierung zusammengefügt. Durch dieses Vorgehen wurde die Subjektivität einzelner Interpretationen reduziert und eine möglichst transparente Auswertung gewährleistet.

## Quantitative Methode

Im zweiten Teil unserer Studie führten wir eine quantitative Online-Umfrage durch. Diese bestand aus einem Between-Subjects Faktor, welcher den Unterschied zwischen einer evaluativen KI und einer empfehlenden KI untersuchte, sowie aus einem Within-Subject Faktor, um den Unterschied zwischen der Bewertung von Social Media Posts mit und ohne Unterstützung einer KI zu untersuchen. Es handelte sich bei unserer quantitativen Methode demnach um ein Mixed Design.

Die Rekrutierung erfolgte über einen schriftlichen Aufruf, der einen Link zur Umfrage enthielt (siehe [Anhang 1](#anhang-rekrutierung)). Den Text verbreiteten wir im Bekanntenkreis, sowie im „Studien und Umfragen“-Forum des Allgemeinen Studierendenausschusses der Universität zu Lübeck. Die Teilnehmenden mussten mindestens 18 Jahre alt sein, um den Datenschutz gemäß der Datenschutz-Grundverordnung gewährleisten zu können. Zudem setzten wir gute Deutschkenntnisse voraus, da unsere Umfrage ausschließlich auf Deutsch verfügbar war und mangelndes Sprachverständnis die Ergebnisse hätte beeinträchtigen können. Personen, die im Sommersemester 2025 an der Veranstaltung „Statistik und Methoden der Nutzerforschung“ der Universität zu Lübeck teilnahmen, waren ebenfalls von der Teilnahme ausgeschlossen, um Verzerrungen durch inhaltliche Vorkenntnisse zu vermeiden. Aufgrund des Interfaces musste die Umfrage an einem PC oder Laptop durchgeführt werden. Studenten der Universität zu Lübeck konnten als Vergütung eine Versuchspersonenstunde erhalten. Wir setzten uns das Ziel, mindestens 30 ausgefüllte Umfragen für eine ausreichend große Stichprobe zu erhalten, die im Zeitraum vom 24.05.2025 bis zum 02.06.2025 abgeschlossen werden mussten.

Nachdem die Teilnehmenden den Link aus dem Rekrutierungstext aufriefen, wurden sie zunächst durch einen Text über die Studie und den Datenschutz aufgeklärt. Sofern sie diesen zustimmten, startete die mehrteilige Umfrage. Im Pre-Test-Fragebogen wurde die Demografik der Teilnehmenden abgefragt und ein Tutorial für die anschließenden Aufgaben gezeigt. Die Teilnehmenden mussten neben der Bewertung von Social Media Posts einen sekundären Task bearbeiten. Hierbei wurde in der rechten oberen Ecke ein Licht angezeigt, welches zwischen blau und rot wechselte. Sobald das Licht rot schien, musste ein Button in der linken oberen Ecke gedrückt werden. Dieser Task diente zur Messung der mentalen Belastung. Nach dem Tutorial wurde das Baseline Experiment durchgeführt. Hierfür mussten alle Teilnehmenden zehn Posts ohne die Unterstützung von KI bewerten. Sie gaben an, ob sie den Post als Misinformation einschätzten und wie sicher sie sich mit dieser Entscheidung waren. Anschließend folgte ein Post-Baseline-Fragebogen, der den subjektiven Workload erfasste. Im nächsten Schritt wurden die Befragten randomisiert einem evaluativen oder empfehlenden Systemtyp zugeordnet. Es mussten erneut zehn Posts bewertet werden, diesmal jedoch mit der Unterstützung des jeweiligen KI-Typen. Bei jedem Post mussten die Teilnehmenden mindestens eine Frage an die KI stellen. Sie konnten jedoch auch mehrere Fragen stellen und mussten währenddessen weiterhin den sekundären Task ausführen. Nach der Bewertung der zehn Posts musste ein weiterer Fragebogen beantwortet werden, welcher Fragen zum Workload, zur User Experience und zum Vertrauen in das KI-System beinhaltete. Die Studie endete mit einem kurzen Debriefing, sowie einer Umfrage zum Erhalt der Versuchspersonenstunden. Der gesamte Ablauf der Studie ist in Diagramm @fig-ablauf veranschaulicht.

Zur Erfassung des Workloads verwendeten wir das DLR Workload Assessment Tool nach [@grippenkoven_dlr-wat_2018]. Die Skala bestand aus acht Items, mit denen die subjektive Einschätzung der momentanen Beanspruchung abgefragt wurde. Die Teilnehmenden mussten die einzelnen Items auf einer numerischen Skala von 0 bis 200 bewerten, welche von sehr stark unterbeansprucht (0) über optimal (100) bis sehr stark überbeansprucht (200) ging. Die Subskalen summierten wir zu einem Gesamtwert des Workloads auf und bildeten anschließend den Mittelwert. Die User Experience fragten wir mit Hilfe des User Experience Questionaire nach [@laugwitz_construction_2008] ab. Der Fragebogen bestand aus 26 Items, welche sechs Dimensionen der User Experience behandelten: Attraktivität, Durchschaubarkeit, Originalität, Stimulation, Steuerbarkeit, Effizienz. Die einzelnen Items bestanden jeweils aus einem Paar von Eigenschaften, welche sich auf einer 7-Punkte-Skala gegenüberstanden. Ein Beispiel für ein solches Item war langweilig (1) bis spannend (7). Für die sechs Dimensionen wurde ein gemeinsamer Mittelwert berechnet, wobei einzelne Items zur Sicherstellung der Skalenkonsistenz invertiert wurden. Um das Vertrauen in das KI-System zu untersuchen, verwendeten wir eine ins Deutsche übersetzte Version der Human-Computer Trust 2 (HCT2) Skala nach [@madsen_measuring_2000]. In dieser Studie nutzten wir folgende drei Dimensionen: Perceived Reliability (zu Deutsch: Wahrgenommene Zuverlässigkeit), Perceived Technical Competence (zu Deutsch: Wahrgenommene technische Kompetenz) und Perceived Understandability (zu Deutsch: Wahrgenommene Verständlichkeit). Jede Dimension operationalisierten wir durch fünf Items. Die Teilnehmenden mussten jede Aussage auf einer sechs-stufigen Likert-Skala von stimmt gar nicht (1) bis stimmt völlig (6) bewerten. Anschließen wurde ebenfalls ein gemeinsamer Mittelwert für die drei Dimensionen berechnet.

Wir analysierten die gesammelten Daten unter Anwendung mehrerer Tests. Zum einen untersuchten wir, ob sich der Workload bei Unterstützung durch KI signifikant von dem ohne KI-Einsatz unterschied. Um dies zu testen, führten wir einen zweiseitigen t-Test für abhängige Stichproben durch. Der KI-Einsatz diente dabei als unabhängige und der Workload als abhängige Variable. Des Weiteren überprüften wir, ob sich die User Experience mit einer evaluativen KI signifikant von der mit einer empfehlenden KI unterschied. Hierbei führten wir einen gerichteten t-Test mit unabhängigen Stichproben durch. Die User Experience stellte demnach die abhängige und der KI-Systemtyp die unabhängige Variable dar. Basierend auf unseren deskriptiven Daten lautete unsere Nullhypothese, dass der Mittelwert der User Experience bei der evaluativen KI größer oder gleich dem der empfehlenden KI sei. Im letzten Test analysierten wir den statistischen Zusammenhang zwischen dem Alter der Befragten und dem Vertrauen in das KI-System. Wir berechneten eine Pearson-Korrelation zwischen den zwei Variablen.

![Ablaufdiagramm der Studie](src/survey_diagram.png){#fig-ablauf}

# Ergebnisse

## Qualitative Ergebnisse

Unsere qualitative Analyse bestand aus drei Einzelinterviews mit Studierenden der Medieninformatik an der Universität zu Lübeck. Die zentralen Themen unserer Analyse sind in @tbl-zentrale_themen zusammengefasst und im Folgenden näher beschrieben.

Alle Befragten gaben an, bereits Erfahrungen im Umgang mit KI gesammelt zu haben und Social Media überwiegend für Kommunikations- und Unterhaltungszwecke zu nutzen. Zudem sahen sie KI grundsätzlich als ein geeignetes Werkzeug zur automatisierten Faktenprüfung. So äußerte eine Person, dass durch das Abgleichen der Informationen von der KI eine Art Peer Review geschaffen wird und schloss daraus, „dass KI für \[die Detektion von Misinformationen\] absolut geeignet ist“ (TN_3, Zeile 86).

Allerdings wurde mehrfach betont, dass Transparenz eine entscheidende Voraussetzung für das Vertrauen in die KI ist. So sollten Quellen offengelegt werden, „dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (TN_2, Zeile 99–100) „und vielleicht auch den Analyseweg“ (TN_1, Zeile 102-103). Den Nutzenden war es demnach wichtig, dass im Zweifelsfall zusätzlich zur automatisierten Prüfung durch die KI eine manuelle Kontrolle möglich ist.

Im Hinblick auf die Effektivität der KI-gestützten Überprüfung wurde geäußert, dass die Kennzeichnung der geprüften Inhalte visuell hervorgehoben und schnell erkennbar sein sollte. Eine Person betonte, dass es „auf jeden Fall sehr sichtbar da sein \[sollte\]. Also das heißt, man soll nicht danach suchen müssen“ (TN_3, Z. 218–219). Besonders auf Social Media sei eine solche Sichtbarkeit entscheidend, da Nutzende Inhalte meist nur flüchtig wahrnehmen.

```{r tbl-zentrale_themen, results='asis'}
#| echo: false

df <- data.frame(
  Thema = c("Potenzialbewertung von KI als Werkzeug", 
            "Transparenz durch Quellenangaben", 
            "Sichtbarkeit der Kennzeichnung"),
  Definition = c("Einschätzung, dass KI bei der Identifikation von Misinformation unterstützen kann", 
                 "Forderung, dass die in der Überprüfung verwendeten Quellen offengelegt werden, um Transparenz zu gewährleisten", 
                 "Forderung, dass die Kennzeichnung der KI-Überprüfung visuell hervorgehoben wird, um Effektivität zu gewährleisen"),
  Zitat = c("„[…] Peer Review quasi dadurch zu schaffen […] also glaube ich schon sehr gut, dass KI für sowas absolut geeignet ist“ (TN_3, Zeile 83–86)", 
            "„Die Quellenangabe, dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (TN_2, Zeile 99–100)", 
            "„Es sollte auf jeden Fall sehr sichtbar da sein. Also das heißt, man soll nicht danach suchen müssen“ (TN_3, Zeile 218–219)")
  )

if (knitr::is_latex_output()) {
  kable(df, format = "latex", booktabs = TRUE, caption = "Zentrale Themen der qualitativen Analyse", longtable = TRUE, linesep = "\\addlinespace") %>%
    kable_styling(latex_options = c("hold_position")) %>%
    column_spec(1, width = "4cm") %>%
    column_spec(2, width = "5cm") %>%
    column_spec(3, width = "5cm")
}else if (knitr::is_html_output()) {
  kable(df, format = "html", caption = "Zentrale Themen der qualitativen Analyse", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
    column_spec(1, width = "20%") %>%
    column_spec(2, width = "35%") %>%
    column_spec(3, width = "45%")
}
```

## Quantitative Ergebnisse

### Stichprobe

```{r}
#| echo: false

# Anzahl
anzahl_teilnehmende <- length(data_complete$participantId)

# Anzahl mit empfehlender/evaluativer KI
anzahl_empfehlend <- sum(data_complete$system == "R", na.rm = TRUE)
anzahl_evaluativ <- sum(data_complete$system == "E", na.rm = TRUE)

# Alter (Mittelwert, Standardabweichung, Median, Minimum, Maximum)
alter_mittelwert <- mean(data_complete$age, na.rm = TRUE)
alter_sd <- sd(data_complete$age, na.rm = TRUE)
alter_median <- median(data_complete$age, na.rm = TRUE)
alter_min <- min(data_complete$age, na.rm = TRUE)
alter_max <- max(data_complete$age, na.rm = TRUE)

# Geschlecht (Prozentsätze)
geschlecht_verteilung <- table(data_complete$gender)
geschlecht_prozent <- prop.table(geschlecht_verteilung) * 100
prozent_maennlich <- ifelse("1" %in% names(geschlecht_prozent), geschlecht_prozent[["1"]], 0)
prozent_weiblich <- ifelse("2" %in% names(geschlecht_prozent), geschlecht_prozent[["2"]], 0)
prozent_andere <- sum(geschlecht_prozent[!(names(geschlecht_prozent) %in% c("1", "2"))])

# Vorwissen KI (Mittelwert, Standardabweichung)
vorwissen_mittelwert <- mean(data_complete$aiknowledge, na.rm = TRUE)
vorwissen_sd <- sd(data_complete$aiknowledge, na.rm = TRUE)
```

An unserer Studie nahmen ausschließlich volljährige Personen (*N* = `r anzahl_teilnehmende`) teil. Das Alter der Teilnehmenden lag im Mittel bei *M* = `r round(alter_mittelwert, 1)` (*SD* = `r round(alter_sd, 1)`, *Mdn* = `r alter_median`) bei einer Altersspanne von `r alter_min` bis `r alter_max` Jahren. Die Stichprobe wies somit eine überwiegend junge Altersstruktur auf, zeigte jedoch zugleich eine ausreichende Altersspannbreite, um unterschiedliche Perspektiven abzubilden. `r round(prozent_weiblich, 1)` % der Befragten gaben an, weiblich zu sein, `r round(prozent_maennlich, 1)` % männlich und `r round(prozent_andere, 1)` % ordneten sich einer andere Geschlechtskategorie zu. Zusätzlich erfassten wir das Vorwissen der Teilnehmenden zu Künstlicher Intelligenz, wobei die Selbsteinschätzung auf einer Skala von 1 (sehr wenig) bis 5 (sehr viel) erfolgte. Der Mittelwert lag bei *M* = `r round(vorwissen_mittelwert, 1)` (*SD* = `r round(vorwissen_sd, 1)`), was auf ein durchschnittliches Kenntnisniveau innerhalb der Stichprobe hinweist. Im Rahmen des Between-Subjects Faktors untersuchten wir zwei unabhängige Gruppen in der Stichprobe. Eine Gruppe (*n* = `r anzahl_empfehlend`) erhielt eine empfehlende KI, während die Teilnehmenden der anderen Gruppe (*n* = `r anzahl_evaluativ`) mit einer evaluativen KI interagierten. Diese Einteilung ermöglichte den Vergleich der unterschiedlichen KI-Systeme hinsichtlich weiterer Variablen. Die erhobenen Daten erfüllten durchweg die Einschlusskriterien, sodass kein Fall ausgeschlossen werden musste.

### Deskriptive Statistik

```{r echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false

# Workload
  # Baseline Mittelwert
    data_complete$b_dlr_wat_mean <- rowMeans(data_complete[, c(
    "b_dlr_wat_i",
    "b_dlr_wat_w",
    "b_dlr_wat_e",
    "b_dlr_wat_m",
    "b_dlr_wat_z",
    "b_dlr_wat_a",
    "b_dlr_wat_f",
    "b_dlr_wat_b"
  )])
    
  
  # KI Mittelwert
    data_complete$ki_dlr_wat_mean <- rowMeans(data_complete[, c(
    "ki_dlr_wat_i",
    "ki_dlr_wat_w",
    "ki_dlr_wat_e",
    "ki_dlr_wat_m",
    "ki_dlr_wat_z",
    "ki_dlr_wat_a",
    "ki_dlr_wat_f",
    "ki_dlr_wat_b"
    )])

# UX
  # Items invertieren
  itemsToInvert <- c(3, 4, 5, 9, 10, 12, 17, 18, 19, 21, 23, 24, 25)
  pattern <- paste0("^ueq_(", paste(itemsToInvert, collapse = "|"), ")$")
  columnsToInvert <- grep(pattern, names(data_complete), value = TRUE)
  data_UXinverted <- data_complete
  data_UXinverted[columnsToInvert] <- 8 - data_complete[columnsToInvert]

  # Mittelwert
  data_UXinverted <- data_UXinverted %>%
  mutate(ueq_mean = rowMeans(data_UXinverted[, paste0("ueq_", 1:26)]))
  
  # in evaluativ und empfehlend aufteilen
  data_UXinverted <- data_UXinverted %>%
  mutate(
    ueq_mean = rowMeans(select(., paste0("ueq_", 1:26)), na.rm = TRUE),
    ueq_e_mean = if_else(system == "E", ueq_mean, NA_real_),
    ueq_r_mean = if_else(system == "R", ueq_mean, NA_real_)
  )
  
# HCT2
  # Mittelwert
  data_complete <- data_complete %>%
  mutate(hct_mean = rowMeans(select(., hct_r01:hct_u05)))
  

#Cronbachs Alpha Berechnung
a <- data_complete %>%
select(starts_with("b_dlr_wat_")) %>%
psych::alpha(check.keys = TRUE)

alpha_b_dlr_wat <- round(a$total$raw_alpha, 2)

b <- data_complete %>%
select(starts_with("ki_dlr_wat_")) %>%
psych::alpha(check.keys = TRUE)

alpha_ki_dlr_wat <- round(b$total$raw_alpha, 2)

c <- data_UXinverted %>%
  filter(system == "E") %>%
  select(paste0("ueq_", 1:26)) %>%
  psych::alpha(check.keys = TRUE)

alpha_ueq_e <- round(c$total$raw_alpha, 2)

d <- data_UXinverted %>%
  filter(system == "R") %>%
  select(paste0("ueq_", 1:26)) %>%
  psych::alpha(check.keys = TRUE)

alpha_ueq_r <- round(d$total$raw_alpha, 2)

e <- data_complete %>%
select(starts_with("hct_")) %>%
psych::alpha(check.keys = TRUE)

alpha_hct <- round(e$total$raw_alpha, 2)
```

Unsere Deskriptive Statistik ist in @tbl-deskriptive_statistik dargestellt. Nach den Kriterien von George und Mallery [-@george_spss_2010] zeigte die von uns verwendete Skala zur Erfassung des Workloads sowohl in der Bedingung mit als auch ohne KI-Einsatz eine interne Konsistenz im akzeptablen Bereich (Cronbachs Alpha = `r sub("^0", "", as.character(alpha_b_dlr_wat))`). Die Fragebögen zur User Experience wiesen sowohl für die evaluative (Cronbachs Alpha = `r sub("^0", "", as.character(alpha_ueq_e))`) als auch für die empfehlende KI (Cronbachs Alpha = `r sub("^0", "", as.character(alpha_ueq_r))`) eine exzellente interne Konsistenz auf. Gleiches galt für die HCT2-Skala (Cronbachs Alpha = `r sub("^0", "", as.character(alpha_hct))`), die wir zur Messung des Vertrauens in das KI-System verwendeten. Demnach verfügten alle verwendeten Messinstrumente über eine ausreichende Reliabilität, um in der weiteren Analyse aussagekräftige Ergebnisse zu liefern. Der durchschnittliche Workload mit KI (*M* = `r round(mean(data_complete$ki_dlr_wat_mean), 1)`) lag über dem des Workloads ohne KI (*M* = `r round(mean(data_complete$b_dlr_wat_mean), 1)`). Ebenso lag der Mittelwert der User Experience mit empfehlender KI (*M* = `r round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`) über dem Mittelwert der User Experience mit evaluativer KI (*M* = `r round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`). Das Vertrauen in das KI-System, gemessen mithilfe der HCT2-Skala, lag im Mittel bei *M* = `r round(mean(data_complete$hct_mean), 1)` auf einer Skala von 1 bis 6. Dies lies ein mittleres bis leicht positives Vertrauen der gesamten Stichprobe vermuten. Allerdings zeigte die Standardabweichung (*SD* = `r round(sd(data_complete$hct_mean), 1)`), dass die Bewertungen des Vertrauens in das KI-System eine mäßige Streuung aufwiesen. Der Median und der Mittelwert der jeweiligen Variablen unterschieden sich nur gering, was darauf hindeutete, dass die Verteilungen der Skalenwerte weitgehend symmetrisch waren. Es gab demnach keine oder nur wenige extreme Ausreißer, die den Mittelwert verzerren würden.

```{r tbl-deskriptive_statistik, results='asis', echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false

alpha_strs <- sapply(
  c(alpha_b_dlr_wat, alpha_ki_dlr_wat, alpha_ueq_e, alpha_ueq_r, alpha_hct),
  function(x) sub("^0", "", as.character(x))
)

df <- data.frame(
  Variable = c( 
            "Workload ohne KI",
            "Workload mit KI",
            "User Experience (UEQ) mit evaluativer KI",
            "User Experience (UEQ) mit empfehlender KI",
            "Vertrauen in das KI-System (HCT2)"
            ),
  "Anzahl der Records" = c(
                 sum(!is.na(data_complete$b_dlr_wat_mean)),
                 sum(!is.na(data_complete$ki_dlr_wat_mean)),
                 sum(!is.na(data_UXinverted$ueq_e_mean)),
                 sum(!is.na(data_UXinverted$ueq_r_mean)),
                 sum(!is.na(data_complete$hct_mean))
                 ),
  "Cronbachs Alpha" = c(alpha_strs),
  Mittelwert = c(
                 round(mean(data_complete$b_dlr_wat_mean), 1),
                 round(mean(data_complete$ki_dlr_wat_mean), 1),
                 round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1),
                 round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1),
                 round(mean(data_complete$hct_mean), 1)
                 ),
  Median = c(
                 round(median(data_complete$b_dlr_wat_mean), 2),
                 round(median(data_complete$ki_dlr_wat_mean), 2),
                 round(median(data_UXinverted$ueq_e_mean, na.rm = TRUE), 2),
                 round(median(data_UXinverted$ueq_r_mean, na.rm = TRUE), 2),
                 round(median(data_complete$hct_mean), 2)
                 ),
  Min = c(
                 round(min(data_complete$b_dlr_wat_mean)),
                 round(min(data_complete$ki_dlr_wat_mean)),
                 round(min(data_UXinverted$ueq_e_mean, na.rm = TRUE)),
                 round(min(data_UXinverted$ueq_r_mean, na.rm = TRUE)),
                 round(min(data_complete$hct_mean))
                 ),
  Max = c(
                 round(max(data_complete$b_dlr_wat_mean)),
                 round(max(data_complete$ki_dlr_wat_mean)),
                 round(max(data_UXinverted$ueq_e_mean, na.rm = TRUE)),
                 round(max(data_UXinverted$ueq_r_mean, na.rm = TRUE)),
                 round(max(data_complete$hct_mean))
                 ),
  Standardabweichung = c(
                 round(sd(data_complete$b_dlr_wat_mean), 1),
                 round(sd(data_complete$ki_dlr_wat_mean), 1),
                 round(sd(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1),
                 round(sd(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1),
                 round(sd(data_complete$hct_mean), 1)
                 )
)

if (knitr::is_latex_output()) {
  kable(
    df,
    col.names = c("Variable", "Anzahl der Records", "Cronbachs Alpha", "Mittelwert", "Median", "Min", "Max", "SD"),
    format = "latex",
    booktabs = TRUE,
    caption = "Deskriptive Statistik",
    longtable = TRUE,
    linesep = "\\addlinespace") %>%
    kable_styling(latex_options = c("hold_position")) %>%
    column_spec(1, width = "2cm") %>%
    column_spec(2, width = "1.7cm") %>%
    column_spec(3, width = "1.7cm") %>%
    column_spec(4, width = "1.5cm") %>%
    column_spec(5, width = "1.5cm") %>%
    column_spec(8, width = "1.7cm")
}else if (knitr::is_html_output()) {
  kable(
    df,
    col.names = c("Variable", "Anzahl der Records", "Cronbachs Alpha", "Mittelwert", "Median", "Min", "Max", "Standardabweichung"),
    format = "html",
    caption = "Deskriptive Statistik",
    escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
    column_spec(1, width = "30%") %>%
    column_spec(2, width = "20%") %>%
    column_spec(3, width = "10%") %>%
    column_spec(4, width = "10%") %>%
    column_spec(5, width = "10%")
}
```

### Inferenzstatistik

```{r}
#| echo: false

# t-Test Workload mit with/without
ttest_workload_with_without <- t.test(data_complete$b_dlr_wat_mean, data_complete$ki_dlr_wat_mean, paired = TRUE)

  #Cohen's d
  diff_workload <- data_complete$b_dlr_wat_mean - data_complete$ki_dlr_wat_mean
  mean_diff_workload <- mean(diff_workload)
  sd_diff_workload <- sd(diff_workload)
  cohens_d_workload <- mean_diff_workload / sd_diff_workload

# t-Test UEQ mit System
data_KIsystem <- data_UXinverted %>%
  filter(system == "E" | system == "R")

ttest_ueq_system <- t.test(data_KIsystem$ueq_mean ~ data_KIsystem$system, alternative = "less")

  #Cohen's d
  group_E <- data_KIsystem %>% filter(system == "E") %>% pull(ueq_mean)
  group_R <- data_KIsystem %>% filter(system == "R") %>% pull(ueq_mean)
  mean_E <- mean(group_E)
  mean_R <- mean(group_R)
  sd_E <- sd(group_E)
  sd_R <- sd(group_R)
  n_E <- length(group_E)
  n_R <- length(group_R)
  s_pooled <- sqrt( ((n_E - 1) * sd_E^2 + (n_R - 1) * sd_R^2) / (n_E + n_R - 2) )
  cohens_d_ueq <- (mean_E - mean_R) / s_pooled

# Korrelation HCT2 mit Alter
cor_hct_alter <- cor.test(data_complete$age, data_complete$hct_mean, method = "pearson")
```

In @fig-plot_workload_kisystem ist der Vergleich des subjektiven Workloads zwischen Baseline und KI-Bedingung dargestellt. Ohne die Unterstützung von KI (*M* = `r round(mean(data_complete$b_dlr_wat_mean), 1)`, *SD* = `r round(sd(data_complete$b_dlr_wat_mean), 1)`) berichteten die Teilnehmenden einen signifikant geringeren Workload als mit der Unterstützung von KI (*M* = `r round(mean(data_complete$ki_dlr_wat_mean), 1)`, *SD* = `r round(sd(data_complete$ki_dlr_wat_mean), 1)`, *t* = `r round(ttest_workload_with_without$statistic, 2)`, *p* \< .001, d = `r round(cohens_d_workload, 2)`). Dies deutete darauf hin, dass der Einsatz von KI die Teilnehmenden mental mehr beanspruchte, als die Beurteilung der Posts ohne den Einsatz von KI. Die Effektstärke nach Cohen [-@cohen_statistical_1988] entsprach einem kleinem bis mittelerem Effekt.

In @fig-plot_ueq_system ist der Vergleich der User Experience zwischen empfehlender und evaluativer KI dargestellt. Die Differenz der durchschnittlichen User Experience mit empfehlender KI (*M* = `r round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`, *SD* = `r round(sd(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`) und evaluativer KI (*M* = `r round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`, *SD* = `r round(sd(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`) war signifikant (*t*(`r round(ttest_ueq_system$parameter, 0)`) = `r round(ttest_ueq_system$statistic, 2)`, *p* = `r sub("^0", "", formatC(ttest_ueq_system$p.value, format = "f", digits = 3))`, d = `r round(cohens_d_ueq, 2)`). Dies deutete darauf hin, dass der Einsatz einer empfehlenden KI mit einer verbesserten User Experience einherging, sodass unsere Nullhypothese verworfen werden konnte. Die Effektstärke nach Cohen [-@cohen_statistical_1988] entsprach einem kleinem bis mittelerem Effekt.

In @fig-plot_hct_age ist der Zusammenhang zwischen dem Alter der Teilnehmenden und dem Vertrauen in das KI-System dargestellt. Es bestand ein signifikanter Zusammenhang zwischen den zwei Variablen (*r*(`r cor_hct_alter$parameter`) = `r sub("^0", "", formatC(cor_hct_alter$estimate, format = "f", digits = 2))`, *p* = `r sub("^0", "", formatC(cor_hct_alter$p.value, format = "f", digits = 2))`). Das bedeutete, dass ein höheres Alter mit einem niedrigeren Vertrauen einherging und umgekehrt. Die Effektstärke nach Cohen [-@cohen_statistical_1988] entsprach einem kleinem Effekt.

```{r fig-plot_workload_kisystem, fig.cap="Vergleich der Mittelwerte des Workloads zwischen Baseline und KI-Bedingung (t-Test abhängiger Stichproben)."}
#| echo: false
# Daten in Long-Format
data_long <- data_complete %>%
  select(b_dlr_wat_mean, ki_dlr_wat_mean) %>%
  pivot_longer(cols = everything(), names_to = "system", values_to = "value") %>%
  mutate(system = recode(system, b_dlr_wat_mean = "Baseline", ki_dlr_wat_mean = "KI"))

# Plot
ggplot(data_long, aes(x = system, y = value)) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "blue") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.2) +
  labs(x = "Systemtyp", y = "Workload (DLR)") +
  theme_minimal()
```

```{r fig-plot_ueq_system, fig.cap="Vergleich der Mittelwerte der User Experience zwischen empfehlender und evaluativer KI (t-Test unabhängiger Stichproben)."}
#| echo: false
ggplot(data_KIsystem, aes(x = system , y = ueq_mean)) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "blue") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.2) +
  labs(x = "KI-Systemtyp", y = "User Experience (UEQ)") +
  theme_minimal()
```

```{r fig-plot_hct_age, fig.cap="Zusammenhang zwischen Alter und Vertrauen in das KI-System (Pearson-Korrelation).", echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false
ggplot(data_complete, aes(x = age, y = hct_mean)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  labs(x = "Alter", y = "Vertrauen (HCT)") +
  theme_minimal()
```

# Diskussion

In unserer Studie untersuchen wir, wie KI als Werkzeug die Erkennung von Misinformationen auf Social Media unterstützen kann. Hierfür führten wir Einzelinterviews mit Studierenden durch sowie eine Online-Umfrage im Rahmen eines gemischt faktoriellen Designs. Der Einsatz von KI wird dabei als Within-Subject Faktor betrachtet, während die Art des KI-Systems, evaluativ oder empfehlend, unseren Between-Subject Faktor dargestellt. Die Ergebnisse der Studienabschnitte sind stellenweise nicht konsistent. Unsere primäre Forschungsfrage, ob der Einsatz von KI als Werkzeug die Detektion von Misinformation auf Social Media erleichtert, zeigt einen dieser Widersprüche. Die Teilnehmenden der Interviews empfinden KI als hilfreiche Unterstützung. Im Gegensatz dazu zeigt die Online-Umfrage, dass die Nutzung von KI mit einer höheren mentalen Belastung einhergeht. Für unsere zweite Frage, welche Nutzungsanforderungen an die KI als Werkzeug gestellt werden, können wir in unserem qualitativen Teil zwei zentrale Anforderungen identifizieren. Zum einen fordern die Teilnehmenden einen transparenten Analyseweg der KI und zum anderen eine klare Kennzeichnung der KI-Beurteilungen. Mit unserer quantitativen Analyse können wir unsere letzten zwei Forschungsfragen beantworten. Es zeigte sich, dass die User Experience bei einer empfehlenden KI höher ist als bei einer evaluativen KI. Des Weiteren können wir feststellen, dass mit steigendem Alter das Vertrauen in das KI-System abnimmt.

Obwohl sich die Ergebnisse unserer primären Forschungsfrage widersprechen, stehen sie im Einklang mit bisherigen Studien. Auch dort wird der Einsatz von KI im Bereich der Detektion von Misinformationen als sinnvoll bewertet und gleichzeitig wird betont, dass KI mit Vorsicht einzusetzen ist. Santos [-@santos_artificial_2023] verweist insbesondere auf die Komplexität von Misinformationen und auf die Gefahr, dass KI-Bewertungen ohne menschliche Beteiligung zu Fehlurteilen führen kann. Unsere Studie zeigt darüber hinaus, dass der Einsatz von KI die kognitive Belastung erhöht, was gegen eine effektive Detektion von Misinformationen spricht. Wir vermuten, dass eine geschulte Verwendung die kognitive Belastung senkt. Daraus lässt sich schließen, dass nicht nur die KI adäquat trainiert werden muss [@gondwe_can_2025], sondern ebenso die Menschen, die mit ihr arbeiten. Nur so lassen sich sowohl korrekte Ergebnisse erzielen als auch die Effektivität des KI-Einsatzes steigern.

Die in unseren Interviews identifizierten Nutzungsanforderungen werden ebenfalls durch bisherige Forschungsergebnisse gestützt. Moon und Kahlor [-@moon_fact-checking_2025] kommen zu dem Schluss, dass die Platzierung der Kennzeichnung einer KI-Prüfung entscheidend für das Vertrauen der Nutzenden ist. Unsere Befunde ergänzen, dass die Sichtbarkeit der Kennzeichnung zudem entscheidend für die Effektivität der KI ist. Gerade im schnelllebigen Umfeld des Internets ist dies von zentraler Bedeutung. Daraus lassen sich wichtige Richtlinien für eine einheitliche und klar erkennbare Kennzeichnung von KI-Werkzeugen ableiten. Das Ziel sollte sein, dass Nutzende die Beteiligung von KI auf den ersten Blick erkennen und zuordnen können. Die Nutzungsanforderung eines transparenten Analyseprozesses stellt eine Ergänzung der Studie von Moon und Kahlor [-@moon_fact-checking_2025] dar. Die Autoren fanden heraus, dass KI als unparteiischer Akteur in der Informationsanalyse wahrgenommen werden kann. Sie räumen jedoch ein, dass ihre Untersuchung menschliche Einflussfaktoren hinter der KI nicht berücksichtigt. Unsere Interviews zeigen, dass zur Beurteilung der Objektivität der Analyse der Analyseweg offengelegt werden muss. Daraus lassen sich Richtlinien ableiten, die KI-Systeme verpflichten, ihre Entscheidungsgrundlagen transparent zu machen.

Unser Befund, dass die empfehlende KI zu einer besseren User Experience führt als die evaluative KI, steht zunächst im Widerspruch zur Forderung nach einem transparenten Analyseprozess. Dieses Ergebnis lässt sich jedoch durch Erkenntnisse aus der Urteils- und Entscheidungspsychologie erklären. Kahnemans [-@kahneman_thinking_2011] Konzept der kognitiven Leichtigkeit beschreibt die menschliche Tendenz, kognitive Anstrengung zu vermeiden. Menschen bevorzugen Denkwege, die schnell und intuitiv zugänglich sind. In unserer Studie erfordert die evaluative KI eine tiefere Auseinandersetzung mit einzelnen Argumenten und somit einen höheren kognitiven Aufwand. Dies könnte die geringere User Experience mit dem evaluativen System erklären. Der Einsatz empfehlender KI-Systeme sollte jedoch kritisch hinterfragt werden. Solche Systeme sind vor allem sinnvoll, wenn sie auf überprüfbaren Fakten beruhen. In sensiblen oder mehrdeutigen Kontexten hingegen kann eine evaluative, transparent argumentierende KI notwendig sein, um die Entscheidungsqualität langfristig zu sichern.

Montag et al. [-@montag_trust_2024] identifizieren das Alter als einen relevanten Einflussfaktor auf das Vertrauen in KI. Sie behandeln es jedoch nur als Kovariable in ihrer Studie und analysieren den Faktor nicht genauer. Unser Befund ergänzt diese Erkenntnis, indem wir feststellen, dass das Vertrauen in KI mit zunehmendem Alter abnimmt. Dieses Ergebnis ist insbesondere vor dem Hintergrund bedeutsam, dass ältere Menschen laut Ahmed et al. [-@ahmed_social_2023] dazu neigen, häufiger Misinformationen auf Social Media zu vertrauen. Im Kontext der Bekämpfung von Misinformationen ist es daher essenziell, altersdifferenzierte Strategien zu entwickeln. Für die Zielgruppe älterer Nutzenden könnten alternative Ansätze erforderlich sein.

Eine zentrale Limitation unserer Studie betrifft die Altersstruktur der Stichproben. In den qualitativen Interviews wurden ausschließlich junge Studierende befragt. Auch unsere Online-Umfrage wies eine hohe Konzentration von Teilnehmenden im Alter von Anfang 20 auf. Diese eingeschränkte Altersdiversität führt dazu, dass die Korrelation zwischen Alter und Vertrauen in KI nur eine geringe Aussagekraft hat. Zudem liegt die Vermutung nahe, dass die positive Bewertung des KI-Einsatzes zur Detektion von Misinformation in den Interviews zumindest teilweise durch die Altersgruppe bedingt ist. Ein weiterer methodischer Schwachpunkt besteht darin, dass den Teilnehmenden das verwendete KI-System vor der Studie nicht bekannt war. Dies könnte die Messung des empfundenen Workloads verzerrt haben, da die Nutzung eines neuen, unvertrauten Werkzeugs zusätzlichen Aufwand erfordert. Das Ergebnis spiegelt somit nicht zwangsläufig die Bedingungen einer realen Anwendungssituation wider, in der die Nutzenden bereits mit dem System vertraut sind.

Unsere Ergebnisse verdeutlichen, dass der Einsatz von KI zur Erkennung von Misinformation noch umfassend erforscht werden muss. Künftige Studien sollten gezielt eine ausgewogene Altersverteilung in ihren Stichproben sicherstellen, um die Rolle des Alters im Vertrauensverhältnis zur KI differenzierter analysieren zu können. Zudem erscheint es sinnvoll, zu untersuchen, wie sich der wahrgenommene Workload bei längerer Nutzung des KI-Systems verändert. Ebenso wäre es bedeutsam, die Forderung nach einer transparenten Kennzeichnung im Rahmen quantitativer Studien zu validieren.

Unsere Studie zeigt, dass KI ein bedeutendes Werkzeug zur Bewältigung der zunehmenden Informationsflut sein kann, insbesondere im Kampf gegen Misinformation. Dennoch ist der Forschungsstand bisher unzureichend, um eine effektive und verantwortungsvolle Implementierung zu gewährleisten. Deshalb ist eine vertiefte Erforschung dieses Feldes dringend erforderlich.

# Referenzen {.unnumbered}

::: {#refs}
:::

# Anhänge

## Anhang 1 - Rekrutierungstext {#anhang-rekrutierung .unnumbered}

**Online-Studie zur Erkennung von Misinformation auf Social Media**

Hast du schonmal einen Post auf Social Media gesehen und warst dir nicht sicher, ob er wahr oder falsch ist? Misinformation auf Social Media ist oft schwer zu erkennen. In unsere Online-Studie untersuchen wir, inwiefern Künstliche Intelligenz dabei unterstützen kann, solche Inhalte besser zu identifizieren.

Du kannst an der Studie teilnehmen, wenn du:

-   mindestens 18 Jahre alt bist,
-   gut Deutsch sprichst,
-   einen PC oder ein Tablet zur Verfügung hast (keine Smartphone-Teilnahme möglich),
-   und etwa 60 Minuten Zeit mitbringst.

**Teilnahmelink:**

https://dsslab.hciuse.sh/study/pilot?groupId=gr-a3

*(Bitte im Browser auf einem PC oder Tablet öffnen.)*

**Vergütung:** Studierende der Medieninformatik oder Psychologie an der Universität zu Lübeck können 1 VP-Stunde erhalten. Wichtig: Teilnehmende an der Veranstaltung SMNF dürfen die Studie nicht bearbeiten.
