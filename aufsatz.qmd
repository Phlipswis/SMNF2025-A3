---
title: "Aufsatz"
date: today

author:
  - Tara Dethlefsen
  - Jonas Joost
  - Vivien Ramhold
  - Niklas von der Fecht
  - Philipp Wisser

lang: de

format:
  html: default
  pdf:
    papersize: a4
    fontsize: 12pt
    number-sections: true
    
bibliography: quellen.bib
csl: apa.csl

editor: visual
---
```{r setup}
#| echo: false
suppressPackageStartupMessages({
  library(kableExtra)
  library(dplyr)
  library(psych)
  library(ggplot2)
  library(tidyr)
})

data_combined <- read.csv("Daten/data_combined.csv")
web_app_data <- read.csv("Daten/web_app_data.csv")

web_app_filtered <- web_app_data %>%
  filter(system %in% c("E", "R"))
web_app_unique <- web_app_filtered %>%
  group_by(participantId) %>%
  summarise(system = first(system), .groups = "drop")
data_complete <- merge(data_combined, web_app_unique, by = "participantId", all.x = TRUE)
```

**Github Repository und Commit-Hash**

-   **Repository:** \[https://github.com/Phlipswis/SMNF2025-A3\]

```{r}
#| echo: false
gitHash = system("git rev-parse HEAD", intern = TRUE)
```

-   **Commit-Hash:** `{r} gitHash`\

**Code of Conduct**

Mit dem Folgenden haben wir gemeinsame Regeln und Grundsätze formuliert, die unser Miteinander und unsere Arbeitsweise leiten.

Ein zentraler Aspekt ist der respektvolle Umgang mit Feedback sowie unterschiedlichen Perspektiven und Meinungen. Deshalb formulieren wir Kritik konstruktiv mit dem Ziel, gemeinsam eine Lösung zu finden. Die Aufteilung der Arbeitslast erfolgt in unserer Gruppe fair und unter Berücksichtigung der individuellen Fähigkeiten. Jedes Gruppenmitglied übernimmt Verantwortung für seine Aufgaben und trägt so aktiv zum Gelingen des Gesamtprojekts bei. Vereinbarte Termine betrachten wir als verbindlich. Sollte ein Termin aus nachvollziehbaren Gründen nicht eingehalten werden können, informieren wir die Gruppe frühzeitig, damit gemeinsam alternative Lösungen gefunden werden können.

Wir verpflichten uns ehrlich, sorgfältig und transparent zu arbeiten. Plagiate, Datenmanipulation und andere Formen wissenschaftlichen Fehlverhaltens lehnen wir ab. Alle verwendeten Quellen werden ordnungsgemäß zitiert, und die Ergebnisse unserer Arbeit sind jederzeit nachvollziehbar dokumentiert.

Zum Schutz der personenbezogenen und sensiblen Daten gehen wir verantwortungsvoll mit den Informationen um, die uns anvertraut werden. Dabei halten wir uns an die geltenden Datenschutzrichtlinien und sorgen dafür, dass Daten nur für die vorgesehenen Zwecke verwendet und vor unbefugtem Zugriff geschützt werden.

Die Nutzung von Künstlicher Intelligenz (KI) beschränkt sich auf die Korrektur von Rechtschreibung und Grammatik sowie das Generieren von R- und Quarto-Code. In allen anderen Fällen wird die Nutzung von KI-Tools gemäß der Richtlinien der American Psychological Association in der 7. Auflage kenntlich gemacht.

# Einleitung

*Einleitung*

# Literaturübersicht

Misinformation stellt ein zentrales Problem auf Social Media dar. Insbesondere seit den Wahlen in den Vereinigten Staaten im Jahr 2016 ist das Interesse gestiegen, diese Misinformationen zu detektieren. Angesichts der Informationsflut ist eine manuelle Verifikation jedoch nicht flächendeckend umsetzbar. KI-gestützte Systeme bieten durch automatisierte Faktenprüfung die Möglichkeit, schneller und umfangreicher zu arbeiten. Neben der automatisierten Faktenprüfung gibt es auch KI-Methoden der Sprach- und Sentimentanalyse. Die Art des KI-Einsatzes ist entscheidend für den Erfolg der Erkennung von Misinformationen [@santos_artificial_2023].

Gondwe [-@gondwe_can_2025] analysierte vor diesem Hintergrund verschiedene KI-Modelle zur Erkennung von Misinformation bezogen auf die erste US-Präsidentschaftsdebatte im Jahr 2024. Deep-Learning-Ansätze wie Bidirectional encoder representations from transformers erreichten die höchste Genauigkeit mit 94,8 Prozent. Diese Methoden sind jedoch aufgrund des hohen Rechenaufwands schwer skalierbar und demnach nicht in Echtzeit realisierbar. Andere Modelle mit geringerem Rechenaufwand machen hingegen Abstriche in der Genauigkeit [@gondwe_can_2025]. Es stellt sich demnach die Frage, welcher Aspekt für die Nutzer bezogen auf die KI als Werkzeug überwiegt.

Ein weiterer Aspekt für den Erfolg der Erkennung von Misinformationen mit Hilfe von KI ist die zeitliche Einbettung. Qin et al. [-@qin_timing_2025] zeigten in einer Studie, dass der Einsatz von KI die Kreativität der Nutzenden beschränkt, sofern zuvor keine eigenen Ideen entwickelt wurden. Diesen Befund wollen wir auf die Bekämpfung von Misinformationen übertragen. Wir vermuten, dass auch hier die zeitliche Einbettung der KI für den Erfolg entscheidend ist.

Nicht nur technische, sondern auch soziale Einflüsse sind wichtig zu betrachten. Lu et al. [-@lu_effects_2022] konnten zeigen, dass Nutzer KI-generiertem Feedback insbesondere dann vertrauen, wenn soziale Hinweise fehlen. Unter sozialem Druck relativiert sich dieses Vertrauen, was die Komplexität der Nutzer-KI-Interaktion unterstreicht. Auf Social Media könnten Kommentare demnach die KI-Einordnung von Misinformationen überschatten.

Alle genannten Studien zeigen, dass KI wirksam gegen Misinformationen auf Social Media eingesetzt werden kann. Die Effektivität hängt jedoch von mehreren Rahmenbedingungen ab. Dazu zählt die unterschiedliche Genauigkeit der Systeme, der Zeitpunkt des Einsatzes und der soziale Kontext. Diese Faktoren wollen wir im Extended Abstract weiter analysieren.

# Methode

## Qualitative Methode

Für die Beantwortung unserer Forschungsfrage entschieden wir uns für einen qualitativen Ansatz, denn wir verfolgen das Ziel, individuelle Erfahrungen und Sichtweisen detailliert zu erfassen und zu verstehen. Im Mittelpunkt steht dabei die Frage, welche Nutzungsanforderungen an KI als Werkzeug zur Unterstützung bei der Detektion von Misinformation auf Social Media bestehen.

Zur Datenerhebung führten wir jeweils ein leitfadengestütztes Interview mit insgesamt drei Teilnehmenden durch. Die Rekrutierung der Teilnehmenden erfolgte gezielt durch persönliche Ansprache. Dabei achteten wir darauf, dass sie über grundlegende Kenntnisse im Umgang mit KI verfügten. Die Interviews wurden entweder online mit Aufzeichnung über OBS-Studio durchgeführt oder vor Ort unter Verwendung eines Smartphone-Diktiergeräts. Vor Beginn der Interviews unterzeichneten alle Teilnehmenden eine Einwilligungserklärung mit Informationen zur Studie, Datenschutz und anonymisierter Auswertung. Die Gespräche wurden anschließend mit der Transkriptionssoftware Whisper verschriftlicht, folgend händisch überarbeitet und anonymisiert.

Für die Analyse verwendeten wir die Thematische Analyse nach Braun und Clarke [-@braun_using_2006]. Ziel war es, aus dem Material übergeordnete Themen zu extrahieren, die zentrale Anforderungen der Nutzenden widerspiegeln. Die Analyse wurde manuell in Microsoft Word durchgeführt und erfolgte induktiv. Zunächst analysierten wir die Transkripte unabhängig voneinander. Anschließend wurden die identifizierten Codes und Themen im Abgleich zusammengeführt. Bei abweichenden Codierungen wurden die Unterschiede besprochen und schließlich zu einer validen und konsistenten Kategorisierung zusammengefügt. Durch dieses Vorgehen wurde die Subjektivität einzelner Interpretationen reduziert und eine möglichst transparente Auswertung gewährleistet.

## Quantitative Methode

Im quantitativen Teil unserer Studie führten wir eine Online-Umfrage durch. Diese bestand aus einem Between-Subjects Design, welches den Unterschied zwischen einer evaluativen KI und einer empfehlenden KI untersucht. Sowie aus einem Within-Subject Design, um den Unterschied zwischen der Bewertung von Social Media Posts mit und ohne Unterstützung einer KI zu untersuchen. Es handelt sich bei unserer quantitativen Methode demnach um ein Mixed Design.

Die Rekrutierung erfolgte über einen schriftlichen Aufruf, der einen Link zur Umfrage enthielt (siehe [Anhang 1](#anhang-rekrutierung)). Den Text verbreiteten wir im Bekanntenkreis, sowie im „Studien und Umfragen“-Forum des Allgemeinen Studierendenausschusses der Universität zu Lübeck. Die Teilnehmenden mussten mindestens 18 Jahre alt sein, um den Datenschutz gemäß der Datenschutz-Grundverordnung gewährleisten zu können. Zudem setzten wir gute Deutschkenntnisse voraus, da unsere Umfrage ausschließlich auf Deutsch verfügbar war und mangelndes Sprachverständnis die Ergebnisse hätte beeinträchtigen können. Personen, die im Sommersemester 2025 an der Veranstaltung „Statistik und Methoden der Nutzerforschung“ der Universität zu Lübeck teilnahmen, waren ebenfalls von der Teilnahme ausgeschlossen, um Verzerrungen durch inhaltliche Vorkenntnisse zu vermeiden. Auf Grund des Interfaces musste die Umfrage an einem PC oder Laptop durchgeführt werden. Studenten der Universität zu Lübeck konnten als Vergütung eine Versuchspersonenstunde erhalten. Wir setzten uns das Ziel, mindestens 30 ausgefüllte Umfragen zu erhalten, die im Zeitraum vom 24.05.2025 bis zum 02.06.2025 abgeschlossen werden mussten.

Nachdem die Teilnehmenden den Link aus dem Rekrutierungstext aufriefen, wurden sie zunächst durch einen Text über die Studie und den Datenschutz aufgeklärt. Sofern sie diesen zustimmten, startete die mehrteilige Umfrage. Im Pre-Test-Fragebogen wurde die Demografik der Teilnehmer und ihre Technikaffinität abgefragt, sowie ein Tutorial für die anschließenden Aufgaben gezeigt. Die Teilnehmer mussten neben der Bewertung von Social Media Posts einen sekundären Task bearbeiten. Hierbei wurde in der rechten oberen Ecke ein Licht angezeigt, welches zwischen blau und rot wechselte. Sobald das Licht rot schien, musste ein Button in der linken oberen Ecke gedrückt werden. Dieser Task diente zur Messung der mentalen Belastung.Nach dem Tutorial wurde das Baseline Experiment durchgeführt. Hierfür mussten alle Teilnehmenden 10 Posts ohne die Unterstützung von KI bewerten. Sie gaben an, ob sie den Post als Misinformation einschätzten und wie sicher sie sich mit dieser Entscheidung waren. Anschließend folgte ein Post-Baseline-Fragebogen, der das subjektive Workload erfasste. Im nächsten Schritt wurden die Befragten randomisiert einem evaluativen oder empfehlenden Systemtyp zugeordnet. Es mussten erneut 10 Posts bewertet werden, diesmal jedoch mit der Unterstützung des jeweiligen KI-Typen. Bei jedem Post mussten die Teilnehmenden mindestens eine Frage an die KI stellen. Sie konnten jedoch auch mehrere Fragen stellen und mussten währenddessen weiterhin den sekundären Task ausführen. Nach der Bewertung der 10 Posts musste ein weiterer Fragebogen beantwortet werden, dieser beinhaltete Fragen zum Workload, zur User Experience und zum Vertrauen in das System. Die Studie endete mit einem kurzen Debriefing, sowie einer Umfrage zum Erhalt der Versuchspersonenstunden. Der gesamte Ablauf der Studie ist in Diagramm @fig-ablauf veranschaulicht.

Zur Erfassung des Workloads verwendeten wir das DLR Workload Assessment Tool nach [@ev_dlr-wat_2018]. Die Skala besteht aus acht Items, mit denen die subjektive Einschätzung der momentanen Beanspruchung abgefragt wurde. Die Teilnehmer mussten die einzelnen Items auf einer numerischen Skala von 0 bis 200 bewerten, welche von sehr stark unterbeansprucht (0) über optimal (100) bis sehr stark überbeansprucht (200) ging. Die Subskalen wurden zu einem Gesamtwert des Workloads aufsummiert. Die User Experience fragten wir mit Hilfe des User Experience Questionaire nach [@laugwitz_construction_2008] ab. Der Fragebogen besteht aus 26 Items, welche sechs Dimensionen der User Experience behandelten: Attraktivität, Durchschaubarkeit, Originalität, Stimulation, Steuerbarkeit, Effizienz. Die einzelnen Items bestanden, jeweils aus einem Paar von Eigenschaften, welche sich auf einer 7-Punkte-Skala gegenüberstanden. Ein Beispiel für ein solches Item ist langweilig (1) bis spannend (7). Für die sechs Dimensionen wurde ein gemeinsamer Mittelwert berechnet, wofür einige Items invertiert wurden. Um das Vertrauen in das System zu untersuchen, verwendeten wir eine ins Deutsche übersetzte Version der Human-Computer Trust 2 (HCT2) Skala nach [@madsen_measuring_2000]. In dieser Studie nutzten wir folgende drei Dimensionen: Perceived Reliability zu Deutsch Wahrgenommene Zuverlässigkeit, Perceived Technical Competence zu Deutsch Wahrgenommene technische Kompetenz und Perceived Understandability zu Deutsch Wahrgenommene Verständlichkeit. Jede Dimension operationalisierten wir durch fünf Items. Die Teilnehmenden mussten jede Aussage auf einer sechs-stufigen Likert-Skala von stimmt gar nicht (1) bis stimmt völlig (6) bewerten. Anschließen wurde für die Dimensionen ein gemeinsamer Mittelwert berechnet.

Wir analysierten die gesammelten Daten unter Anwendung verschiedener Tests. Zum einen untersuchten wir, ob sich der Workload bei Unterstützung durch KI signifikant von dem ohne KI-Einsatz unterschied. Diese Fragestellung überprüfte das Ergebnis der qualitativen Analyse, wonach der Einsatz von KI die Erkennung von Misinformationen für Benutzer erleichtert. Um dies zu testen, führten wir einen T-Test für abhängige Stichproben durch, wobei der KI-Einsatz als unabhängige Variable und der Workload als abhängige Variable diente. Des Weiteren untersuchten wir, ob sich die User Experience mit einer evaluativen KI signifikant von der mit einer empfehlenden KI unterschied. Hier führten wir einen T-Test für unabhängige Stichproben durch. Die User Experience stellte demnach die abhängige und der KI-Systemtyp die unabhängige Variable dar. In unserem letzten Test analysierten wir den statistischen Zusammenhang zwischen dem Alter der Befragten und dem Vertrauen in das System. Wir berechneten eine Pearson-Korrelation zwischen dem Alter und dem Mittelwert der HCT2-Skala.

![Ablaufdiagramm der Studie](src/survey_diagram.png){#fig-ablauf}

# Ergebnisse

## Qualitative Ergebnisse

Unsere qualitative Analyse besteht aus drei Einzelinterviews mit Studierenden der Medieninformatik an der Universität zu Lübeck. Hierbei wurden die Personen nach ihren Einschätzungen zu der Nutzung von KI bei der Erkennung von Misinformationen auf sozialen Medien befragt. Ziel war es, Anforderungen, Erwartungen und potenzielle Probleme solcher Systeme aus Sicht der Nutzenden zu identifizieren. Die zentralen Themen unserer Analyse sind in @tbl-zentrale_themen zusammengefasst und im Folgenden näher beschrieben.

Alle Befragten gaben an, bereits Erfahrungen im Umgang mit KI gesammelt zu haben und soziale Medien überwiegend für Kommunikations- und Unterhaltungszwecke zu nutzen. Zudem sehen sie KI grundsätzlich als ein geeignetes Werkzeug zur automatisierten Faktenprüfung. So äußerte eine Person, dass durch das Abgleichen der Informationen von der KI eine Art Peer Review geschaffen wird und schloss daraus, „dass KI für \[die Detektion von Misinformationen\] absolut geeignet ist“ (TN_3, Zeile 86).

Allerdings wurde mehrfach betont, dass Transparenz eine entscheidende Voraussetzung für das Vertrauen in die KI ist. So sollten Quellen offengelegt werden, „dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (TN_2, Zeile 99–100) „und vielleicht auch den Analyseweg“ (TN_1, Zeile 102-103). Den Nutzenden ist es demnach wichtig, dass im Zweifelsfall zusätzlich zur automatisierten Prüfung durch die KI eine manuelle Kontrolle möglich ist.

Im Hinblick auf die Effektivität der KI-gestützten Überprüfung wurde geäußert, dass die Kennzeichnung der geprüften Inhalte visuell hervorgehoben und schnell erkennbar sein sollte. Eine Person betonte, dass es „auf jeden Fall sehr sichtbar da sein \[sollte\]. Also das heißt, man soll nicht danach suchen müssen“ (TN_3, Z. 218–219). Besonders in sozialen Medien ist eine solche Sichtbarkeit entscheidend, da Nutzende Inhalte meist nur flüchtig wahrnehmen. Eine deutlich erkennbare Markierung kann in diesem Kontext dazu beitragen, die Wirksamkeit der KI-Überprüfung im Alltag zu erhöhen.

In den Interviews zeigte sich deutlich, dass die inhaltliche Richtigkeit der Überprüfungen gegenüber einer schnellen Verfügbarkeit priorisiert wurde. So urteilte eine der Interviewten: „das braucht ein bisschen, aber dafür ist es dann richtig eingeordnet“ (TN_1, Z. 179–180). Diese Einschätzung ist besonders relevant, da verschiedene KI-Modelle jeweils Kompromisse in einer der beiden Kategorien eingehen. Wie bereits in unserer Literaturanalyse dargelegt, erfordern Modelle mit besonders hoher Genauigkeit einen derart hohen Rechenaufwand, dass sie für eine Echtzeit-Anwendung ungeeignet sind [@gondwe_can_2025]. Das Ergebnis unserer Interviews ist jedoch, dass eine hohe inhaltliche Präzision gegenüber einer sofortigen Einordnung klar bevorzugt wird.

```{r tbl-zentrale_themen, results='asis'}
#| echo: false

df <- data.frame(
  Thema = c("Potenzialbewertung von KI als Werkzeug", 
            "Transparenz durch Quellenangaben", 
            "Sichtbarkeit der Kennzeichnung", 
            "Priorisierung der inhaltlichen Korrektheit"),
  Definition = c("Einschätzung, dass KI bei der Identifikation von Misinformation unterstützen kann", 
                 "Forderung, dass die in der Überprüfung verwendeten Quellen offengelegt werden, um Transparenz zu gewährleisten", 
                 "Forderung, dass die Kennzeichnung der KI-Überprüfung visuell hervorgehoben wird, um Effektivität zu gewährleisen", 
                 "Bewertung, dass die inhaltliche Richtigkeit der Überprüfung wichtiger ist als deren schnelle Verfügbarkeit"),
  Zitat = c("„[…] Peer Review quasi dadurch zu schaffen […] also glaube ich schon sehr gut, dass KI für sowas absolut geeignet ist“ (TN_3, Zeile 83–86)", 
            "„Die Quellenangabe, dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (TN_2, Zeile 99–100)", 
            "„Es sollte auf jeden Fall sehr sichtbar da sein. Also das heißt, man soll nicht danach suchen müssen“ (TN_3, Zeile 218–219)", 
            "„[…] dann speichert es falsch eingeordnet ab. Dann bringt einem das auch nichts, als wenn man sagt, das braucht ein bisschen, aber dafür ist es dann richtig eingeordnet und jeder kann es richtig abspeichern“ (TN_1, Zeile 177–180)")
)

if (knitr::is_latex_output()) {
  kable(df, format = "latex", booktabs = TRUE, caption = "Zentrale Themen der qualitativen Analyse", longtable = TRUE, linesep = "\\addlinespace") %>%
    kable_styling(latex_options = c("hold_position")) %>%
    column_spec(1, width = "4cm") %>%
    column_spec(2, width = "5cm") %>%
    column_spec(3, width = "5cm")
}else if (knitr::is_html_output()) {
  kable(df, format = "html", caption = "Zentrale Themen der qualitativen Analyse", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
    column_spec(1, width = "20%") %>%
    column_spec(2, width = "35%") %>%
    column_spec(3, width = "45%")
}
```

## Quantitative Ergebnisse

### Stichprobe

```{r}
#| echo: false

# Anzahl
anzahl_teilnehmende <- length(data_complete$participantId)

# Anzahl mit empfehlender/evaluativer KI
anzahl_empfehlend <- sum(data_complete$system == "R", na.rm = TRUE)
anzahl_evaluativ <- sum(data_complete$system == "E", na.rm = TRUE)

# Alter (Mittelwert, Standardabweichung, Median, Minimum, Maximum)
alter_mittelwert <- mean(data_complete$age, na.rm = TRUE)
alter_sd <- sd(data_complete$age, na.rm = TRUE)
alter_median <- median(data_complete$age, na.rm = TRUE)
alter_min <- min(data_complete$age, na.rm = TRUE)
alter_max <- max(data_complete$age, na.rm = TRUE)

# Geschlecht (Prozentsätze)
geschlecht_verteilung <- table(data_complete$gender)
geschlecht_prozent <- prop.table(geschlecht_verteilung) * 100
prozent_maennlich <- ifelse("1" %in% names(geschlecht_prozent), geschlecht_prozent[["1"]], 0)
prozent_weiblich <- ifelse("2" %in% names(geschlecht_prozent), geschlecht_prozent[["2"]], 0)
prozent_andere <- sum(geschlecht_prozent[!(names(geschlecht_prozent) %in% c("1", "2"))])

# Vorwissen KI (Mittelwert, Standardabweichung)
vorwissen_mittelwert <- mean(data_complete$aiknowledge, na.rm = TRUE)
vorwissen_sd <- sd(data_complete$aiknowledge, na.rm = TRUE)
```

An unserer Studie nahmen ausschließlich volljährige Personen (*N* = `r anzahl_teilnehmende`) teil. Das Alter der Teilnehmenden lag im Mittel bei `r round(alter_mittelwert, 1)` (*SD* = `r round(alter_sd, 1)`, *Mdn* = `r alter_median`) bei einer Altersspanne von `r alter_min` bis `r alter_max` Jahren. `r round(prozent_weiblich, 1)` % der Befragten gaben an, weiblich zu sein, `r round(prozent_maennlich, 1)` % männlich und `r round(prozent_andere, 1)` % ordneten sich einer andere Geschlechtskategorie zu. Zusätzlich erfassten wir das Vorwissen der Teilnehmenden zu Künstlicher Intelligenz, wobei die Selbsteinschätzung auf einer Skala von 1 (sehr wenig) bis 5 (sehr viel) erfolgte. Der Mittelwert lag bei *M* = `r round(vorwissen_mittelwert, 1)` (*SD* = `r round(vorwissen_sd, 1)`), was auf ein durchschnittliches Kenntnisniveau innerhalb der Stichprobe hinweist. Im Rahmen eines Between-Subjects-Designs untersuchten wir zwei unabhängige Gruppen in der Stichprobe. Eine Gruppe (*n* = `r anzahl_empfehlend`) erhielt eine empfehlende KI, während die Teilnehmer der anderen Gruppe (*n* = `r anzahl_evaluativ`) mit einer evaluativen KI interagierten. Diese Einteilung ermöglichte den Vergleich der unterschiedlichen KI-Systeme hinsichtlich weiterer Variablen. Wir konnten alle erhobenen Daten in die Analyse einbeziehen.

### Deskriptive Statistik

```{r echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false

# Workload
  # Baseline Summe
    data_complete$b_dlr_wat_sum <- rowSums(data_complete[, c(
    "b_dlr_wat_i",
    "b_dlr_wat_w",
    "b_dlr_wat_e",
    "b_dlr_wat_m",
    "b_dlr_wat_z",
    "b_dlr_wat_a",
    "b_dlr_wat_f",
    "b_dlr_wat_b"
  )])
  
  # KI Summe
    data_complete$ki_dlr_wat_sum <- rowSums(data_complete[, c(
    "ki_dlr_wat_i",
    "ki_dlr_wat_w",
    "ki_dlr_wat_e",
    "ki_dlr_wat_m",
    "ki_dlr_wat_z",
    "ki_dlr_wat_a",
    "ki_dlr_wat_f",
    "ki_dlr_wat_b"
    )])

# UX
  # Items invertieren
  itemsToInvert <- c(3, 4, 5, 9, 10, 12, 17, 18, 19, 21, 23, 24, 25)
  pattern <- paste0("^ueq_(", paste(itemsToInvert, collapse = "|"), ")$")
  columnsToInvert <- grep(pattern, names(data_complete), value = TRUE)
  data_UXinverted <- data_complete
  data_UXinverted[columnsToInvert] <- 8 - data_complete[columnsToInvert]

  # Mittelwert
  data_UXinverted <- data_UXinverted %>%
  mutate(ueq_mean = rowMeans(data_UXinverted[, paste0("ueq_", 1:26)]))
  
  # in evaluativ und empfehlend aufteilen
  data_UXinverted <- data_UXinverted %>%
  mutate(
    ueq_mean = rowMeans(select(., paste0("ueq_", 1:26)), na.rm = TRUE),
    ueq_e_mean = if_else(system == "E", ueq_mean, NA_real_),
    ueq_r_mean = if_else(system == "R", ueq_mean, NA_real_)
  )
  
# HCT
  # Mittelwert
  data_complete <- data_complete %>%
  mutate(hct_mean = rowMeans(select(., hct_r01:hct_u05)))
  

#Cronbachs Alpha Berechnung
a <- data_complete %>%
select(starts_with("b_dlr_wat_")) %>%
psych::alpha(check.keys = TRUE)

alpha_b_dlr_wat <- round(a$total$raw_alpha, 2)

b <- data_complete %>%
select(starts_with("ki_dlr_wat_")) %>%
psych::alpha(check.keys = TRUE)

alpha_ki_dlr_wat <- round(b$total$raw_alpha, 2)

c <- data_UXinverted %>%
  filter(system == "E") %>%
  select(paste0("ueq_", 1:26)) %>%
  psych::alpha(check.keys = TRUE)

alpha_ueq_e <- round(c$total$raw_alpha, 2)

d <- data_UXinverted %>%
  filter(system == "R") %>%
  select(paste0("ueq_", 1:26)) %>%
  psych::alpha(check.keys = TRUE)

alpha_ueq_r <- round(d$total$raw_alpha, 2)

e <- data_complete %>%
select(starts_with("hct_")) %>%
psych::alpha(check.keys = TRUE)

alpha_hct <- round(e$total$raw_alpha, 2)
```

Unsere Deskriptive Statistik ist in @tbl-deskriptive_statistik dargestellt. Nach den Kriterien von George und Mallery [-@george-2010] zeigte die von uns verwendete Skala zur Erfassung des Workloads sowohl in der Bedingung mit als auch ohne KI-Einsatz eine interne Konsistenz im akzeptablen Bereich (Cronbachs Alpha = `r sub("^0", "", as.character(alpha_b_dlr_wat))`). Die Fragebögen zur User Experience weisen sowohl für die evaluative als auch für die empfehlende KI mit einem Cronbachs Alpha von über .90 eine exzellente interne Konsistenz auf. Gleiches gilt für HCT2-Skala, die wir zur Messung des Vertrauens in das System verwendeten. Demnach verfügen alle verwendeten Messinstrumente über eine ausreichende Reliabilität, um in der weiteren Analyse aussagekräftige Ergebnisse zu liefern.
Der Mittelwert des Workloads mit KI (*M* = `r round(mean(data_complete$ki_dlr_wat_sum), 1)`) liegt über dem des Workloads ohne KI (*M* = `r round(mean(data_complete$b_dlr_wat_sum), 1)`), genau wie die User Experience mit empfehlender KI (*M* = `r round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`) über der User Experience mit evaluativer KI (*M* = `r round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`) liegt. Das Vertrauen in das System, gemessen mithilfe der HCT2-Skala, liegt im Mittel bei *M* = `r round(mean(data_complete$hct_mean), 1)` auf einer Skala von 1 bis 6. Dies lässt ein mittleres bis leicht positives Vertrauen der gesamten Stichprobe vermuten. Allerdings zeigt die Standardabweichung (*SD* = `r round(sd(data_complete$hct_mean), 1)`), dass die Bewertung des Vertrauens in das System streut.

```{r tbl-deskriptive_statistik, results='asis', echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false

alpha_strs <- sapply(
  c(alpha_b_dlr_wat, alpha_ki_dlr_wat, alpha_ueq_e, alpha_ueq_r, alpha_hct),
  function(x) sub("^0", "", as.character(x))
)

df <- data.frame(
  Variable = c( 
            "Workload ohne KI",
            "Workload mit KI",
            "User Experience (UEQ) mit evaluativer KI",
            "User Experience (UEQ) mit empfehlender KI",
            "Human-Computer Trust"
            ),
  "Anzahl der Records" = c(
                 sum(!is.na(data_complete$b_dlr_wat_sum)),
                 sum(!is.na(data_complete$ki_dlr_wat_sum)),
                 sum(!is.na(data_UXinverted$ueq_e_mean)),
                 sum(!is.na(data_UXinverted$ueq_r_mean)),
                 sum(!is.na(data_complete$hct_mean))
                 ),
  "Cronbachs Alpha" = c(alpha_strs),
  Mittelwert = c(
                 round(mean(data_complete$b_dlr_wat_sum), 1),
                 round(mean(data_complete$ki_dlr_wat_sum), 1),
                 round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1),
                 round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1),
                 round(mean(data_complete$hct_mean), 1)
                 ),
  Median = c(
                 round(median(data_complete$b_dlr_wat_sum), 2),
                 round(median(data_complete$ki_dlr_wat_sum), 2),
                 round(median(data_UXinverted$ueq_e_mean, na.rm = TRUE), 2),
                 round(median(data_UXinverted$ueq_r_mean, na.rm = TRUE), 2),
                 round(median(data_complete$hct_mean), 2)
                 ),
  Min = c(
                 round(min(data_complete$b_dlr_wat_sum)),
                 round(min(data_complete$ki_dlr_wat_sum)),
                 round(min(data_UXinverted$ueq_e_mean, na.rm = TRUE)),
                 round(min(data_UXinverted$ueq_r_mean, na.rm = TRUE)),
                 round(min(data_complete$hct_mean))
                 ),
  Max = c(
                 round(max(data_complete$b_dlr_wat_sum)),
                 round(max(data_complete$ki_dlr_wat_sum)),
                 round(max(data_UXinverted$ueq_e_mean, na.rm = TRUE)),
                 round(max(data_UXinverted$ueq_r_mean, na.rm = TRUE)),
                 round(max(data_complete$hct_mean))
                 ),
  Standartabweichung = c(
                 round(sd(data_complete$b_dlr_wat_sum), 1),
                 round(sd(data_complete$ki_dlr_wat_sum), 1),
                 round(sd(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1),
                 round(sd(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1),
                 round(sd(data_complete$hct_mean), 1)
                 )
)

if (knitr::is_latex_output()) {
  kable(df, format = "latex", booktabs = TRUE, caption = "Deskriptive Statistik", longtable = TRUE, linesep = "\\addlinespace") %>%
    kable_styling(latex_options = c("hold_position")) %>%
    column_spec(1, width = "7cm") %>%
    column_spec(2, width = "2cm") %>%
    column_spec(3, width = "2cm") %>%
    column_spec(4, width = "2cm") %>%
    column_spec(5, width = "2cm")
}else if (knitr::is_html_output()) {
  kable(df, format = "html", caption = "Deskriptive Statistik", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
    column_spec(1, width = "60%") %>%
    column_spec(2, width = "10%") %>%
    column_spec(3, width = "10%") %>%
    column_spec(4, width = "10%") %>%
    column_spec(5, width = "10%")
}
```

### Inferenzstatistik

```{r}
#| echo: false

# T-Test Workload mit with/without
ttest_workload_with_without <- t.test(data_complete$b_dlr_wat_sum, data_complete$ki_dlr_wat_sum, paired = TRUE)

# T-Test UEQ mit System
data_KIsystem <- data_UXinverted %>%
  filter(system == "E" | system == "R")

ttest_ueq_system <- t.test(data_KIsystem$ueq_mean ~ data_KIsystem$system, alternative = "less")

# Korrelation HCT mit Alter
cor_hct_alter <- cor.test(data_complete$age, data_complete$hct_mean, method = "pearson")
```

In @fig-plot_workload_with_without_KI ist der Vergleich des Workloads zwischen Baseline und KI-Bedingung dargestellt. Ohne die Unterstützung von KI (*M* = `r round(mean(data_complete$b_dlr_wat_sum), 1)`, *SD* = `r round(sd(data_complete$b_dlr_wat_sum), 1)`) berichten die Teilnehmenden einen geringeren Workload als mit der Unterstützung von KI ((*M* = `r round(mean(data_complete$ki_dlr_wat_sum), 1)`, *SD* = `r round(sd(data_complete$ki_dlr_wat_sum), 1)`) (*t* = `r round(ttest_workload_with_without$statistic, 2)`, *p* < .001). Dies deutet darauf hin, dass der Einsatz von KI die Teilnehmenden mental mehr beansprucht, als ohne den Einsatz.

In @fig-plot_ueq_system ist der Vergleich der User Experience zwischen empfehlender und evaluativer KI dargestellt. Die Differenz der durchschnittlichen User Experience mit empfehlender KI (*M* = `r round(mean(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`, *SD* = `r round(sd(data_UXinverted$ueq_r_mean, na.rm = TRUE), 1)`) und evaluativer KI (*M* = `r round(mean(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`, *SD* = `r round(sd(data_UXinverted$ueq_e_mean, na.rm = TRUE), 1)`) war signifikant (*t*(`r round(ttest_ueq_system$parameter, 0)`) = `r round(ttest_ueq_system$statistic, 2)`, *p* = `r sub("^0", "", formatC(ttest_ueq_system$p.value, format = "f", digits = 3))`) Dies deutet darauf hin, dass der Einsatz von empfehlender KI eine verbesserte User Experience mit sich bringt.

In @fig-plot_hct_age ist der Zusammenhang zwischen Alter der Teilnehmenden und Vertrauen in das System dargestellt. Es besteht ein Zusammenhang zwischen den beiden Variablen (*r*(`r cor_hct_alter$parameter`) = `r sub("^0", "", formatC(cor_hct_alter$p.value, format = "f", digits = 2))`, *p* = `r sub("^0", "", formatC(cor_hct_alter$p.value, format = "f", digits = 3))`). Das bedeutet, dass ein höheres Alter mit einem niedrigeren Vertrauen einhergingen, und umgekehrt.

```{r fig-plot_workload_with_without_KI, fig.cap="Vergleich der Mittelwerte des Workloads zwischen Baseline und KI-Bedingung (t-Test abhängiger Stichproben)."}
#| echo: false
# Daten in Long-Format
data_long <- data_complete %>%
  select(b_dlr_wat_sum, ki_dlr_wat_sum) %>%
  pivot_longer(cols = everything(), names_to = "system", values_to = "value") %>%
  mutate(system = recode(system, b_dlr_wat_sum = "Baseline", ki_dlr_wat_sum = "KI"))

# Plot
ggplot(data_long, aes(x = system, y = value)) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "blue") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.2) +
  labs(x = "System", y = "Workload (DLR)") +
  theme_minimal()
```


```{r fig-plot_ueq_system, fig.cap="Vergleich der Mittelwerte der User Experience zwischen empfehlender und evaluativer KI (t-Test unabhängiger Stichproben)."}
#| echo: false
ggplot(data_KIsystem, aes(x = system , y = ueq_mean)) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "blue") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.2) +
  labs(x = "KI-System", y = "User Experience (UEQ)") +
  theme_minimal()
```

```{r fig-plot_hct_age, fig.cap="Zusammenhang zwischen Alter und Vertrauen in das KI-System (Pearson-Korrelation).", echo=FALSE, message=FALSE, warning=FALSE}
#| echo: false
ggplot(data_complete, aes(x = age, y = hct_mean)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  labs(x = "Alter", y = "Vertrauen (HCT)") +
  theme_minimal()
```

# Diskussion

*Diskussion*

# Referenzen {.unnumbered}

::: {#refs}
:::

# Anhänge

## Anhang 1 - Rekrutierungstext {#anhang-rekrutierung .unnumbered}

**Online-Studie zur Erkennung von Misinformation auf Social Media**

Hast du schonmal einen Post auf Social Media gesehen und warst dir nicht sicher, ob er wahr oder falsch ist? Misinformation auf Social Media ist oft schwer zu erkennen. In unsere Online-Studie untersuchen wir, inwiefern Künstliche Intelligenz dabei unterstützen kann, solche Inhalte besser zu identifizieren.

Du kannst an der Studie teilnehmen, wenn du:

-   mindestens 18 Jahre alt bist,
-   gut Deutsch sprichst,
-   einen PC oder ein Tablet zur Verfügung hast (keine Smartphone-Teilnahme möglich),
-   und etwa 60 Minuten Zeit mitbringst.

**Teilnahmelink:**

https://dsslab.hciuse.sh/study/pilot?groupId=gr-a3

*(Bitte im Browser auf einem PC oder Tablet öffnen.)*

**Vergütung:** Studierende der Medieninformatik oder Psychologie an der Universität zu Lübeck können 1 VP-Stunde erhalten. Wichtig: Teilnehmende an der Veranstaltung SMNF dürfen die Studie nicht bearbeiten.
