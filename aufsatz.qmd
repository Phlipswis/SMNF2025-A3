---
title: "Aufsatz"
date: today

author:
  - Tara Dethlefsen
  - Jonas Joost
  - Vivien Ramhold
  - Niklas von der Fecht
  - Philipp Wisser

lang: de

format:
  html: default
  pdf:
    papersize: a4
    fontsize: 12pt
    number-sections: true
    
bibliography: quellen.bib
csl: apa.csl

editor: visual
---

**Github Repository und Commit-Hash**

-   **Repository:** \[https://github.com/Phlipswis/SMNF2025-A3\]

```{r}
#| echo: false
gitHash = system("git rev-parse HEAD", intern = TRUE)
```

-   **Commit-Hash:** `{r} gitHash`\

**Code of Conduct**

Mit dem Folgenden haben wir gemeinsame Regeln und Grundsätze formuliert, die unser Miteinander und unsere Arbeitsweise leiten.

Ein zentraler Aspekt ist der respektvolle Umgang mit Feedback sowie unterschiedlichen Perspektiven und Meinungen. Deshalb formulieren wir Kritik konstruktiv mit dem Ziel, gemeinsam eine Lösung zu finden. Die Aufteilung der Arbeitslast erfolgt in unserer Gruppe fair und unter Berücksichtigung der individuellen Fähigkeiten. Jedes Gruppenmitglied übernimmt Verantwortung für seine Aufgaben und trägt so aktiv zum Gelingen des Gesamtprojekts bei. Vereinbarte Termine betrachten wir als verbindlich. Sollte ein Termin aus nachvollziehbaren Gründen nicht eingehalten werden können, informieren wir die Gruppe frühzeitig, damit gemeinsam alternative Lösungen gefunden werden können.

Wir verpflichten uns ehrlich, sorgfältig und transparent zu arbeiten. Plagiate, Datenmanipulation und andere Formen wissenschaftlichen Fehlverhaltens lehnen wir ab. Alle verwendeten Quellen werden ordnungsgemäß zitiert, und die Ergebnisse unserer Arbeit sind jederzeit nachvollziehbar dokumentiert.

Zum Schutz der personenbezogenen und sensiblen Daten gehen wir verantwortungsvoll mit den Informationen um, die uns anvertraut werden. Dabei halten wir uns an die geltenden Datenschutzrichtlinien und sorgen dafür, dass Daten nur für die vorgesehenen Zwecke verwendet und vor unbefugtem Zugriff geschützt werden.

Die Nutzung von Künstlicher Intelligenz (KI) beschränkt sich auf die Korrektur von Rechtschreibung und Grammatik sowie das Generieren von R- und Quarto-Code. In allen anderen Fällen wird die Nutzung von KI-Tools gemäß der Richtlinien der American Psychological Association in der 7. Auflage kenntlich gemacht.

# Einleitung

*Einleitung*

# Literaturübersicht

Misinformation stellt ein zentrales Problem auf Social Media dar. Insbesondere seit den Wahlen in den Vereinigten Staaten im Jahr 2016 ist das Interesse gestiegen, diese Misinformationen zu detektieren. Angesichts der Informationsflut ist eine manuelle Verifikation jedoch nicht flächendeckend umsetzbar. KI-gestützte Systeme bieten durch automatisierte Faktenprüfung die Möglichkeit, schneller und umfangreicher zu arbeiten. Neben der automatisierten Faktenprüfung gibt es auch KI-Methoden der Sprach- und Sentimentanalyse. Die Art des KI-Einsatzes ist entscheidend für den Erfolg der Erkennung von Misinformationen [@santos_artificial_2023].

Gondwe (2025) analysierte vor diesem Hintergrund verschiedene KI-Modelle zur Erkennung von Misinformation bezogen auf die erste US-Präsidentschaftsdebatte im Jahr 2024. Deep-Learning-Ansätze wie Bidirectional encoder representations from transformers erreichten die höchste Genauigkeit mit 94,8 Prozent. Diese Methoden sind jedoch aufgrund des hohen Rechenaufwands schwer skalierbar und demnach nicht in Echtzeit realisierbar. Andere Modelle mit geringerem Rechenaufwand machen hingegen Abstriche in der Genauigkeit [@gondwe_can_2025]. Es stellt sich demnach die Frage, welcher Aspekt für die Nutzer bezogen auf die KI als Werkzeug überwiegt.

Ein weiterer Aspekt für den Erfolg der Erkennung von Misinformationen mit Hilfe von KI ist die zeitliche Einbettung. Qin et al. [-@qin_timing_2025] zeigten in einer Studie, dass der Einsatz von KI die Kreativität der Nutzenden beschränkt, sofern zuvor keine eigenen Ideen entwickelt wurden. Diesen Befund wollen wir auf die Bekämpfung von Misinformationen übertragen. Wir vermuten, dass auch hier die zeitliche Einbettung der KI für den Erfolg entscheidend ist.

Nicht nur technische, sondern auch soziale Einflüsse sind wichtig zu betrachten. Lu et al. [-@lu_effects_2022] konnten zeigen, dass Nutzer KI-generiertem Feedback insbesondere dann vertrauen, wenn soziale Hinweise fehlen. Unter sozialem Druck relativiert sich dieses Vertrauen, was die Komplexität der Nutzer-KI-Interaktion unterstreicht. Auf Social Media könnten Kommentare demnach die KI-Einordnung von Misinformationen überschatten.

Alle genannten Studien zeigen, dass KI wirksam gegen Misinformationen auf Social Media eingesetzt werden kann. Die Effektivität hängt jedoch von mehreren Rahmenbedingungen ab. Dazu zählt die unterschiedliche Genauigkeit der Systeme, der Zeitpunkt des Einsatzes und der soziale Kontext. Diese Faktoren wollen wir im Extended Abstract weiter analysieren.

# Methode

## Qualitative Methode

Für die Beantwortung unserer Forschungsfrage entschieden wir uns für einen qualitativen Ansatz, denn wir verfolgen das Ziel, individuelle Erfahrungen und Sichtweisen detailliert zu erfassen und zu verstehen. Im Mittelpunkt steht dabei die Frage, welche Nutzungsanforderungen an KI als Werkzeug zur Unterstützung bei der Detektion von Misinformation auf Social Media bestehen.

Zur Datenerhebung führten wir jeweils ein leitfadengestütztes Interview mit insgesamt drei Teilnehmenden durch. Die Rekrutierung der Teilnehmenden erfolgte gezielt durch persönliche Ansprache. Dabei achteten wir darauf, dass sie über grundlegende Kenntnisse im Umgang mit KI verfügten. Die Interviews wurden entweder online mit Aufzeichnung über OBS-Studio durchgeführt oder vor Ort unter Verwendung eines Smartphone-Diktiergeräts. Vor Beginn der Interviews unterzeichneten alle Teilnehmenden eine Einwilligungserklärung mit Informationen zur Studie, Datenschutz und anonymisierter Auswertung. Die Gespräche wurden anschließend mit der Transkriptionssoftware Whisper verschriftlicht, folgend händisch überarbeitet und anonymisiert.

Für die Analyse verwendeten wir die Thematische Analyse nach Braun und Clarke. Ziel war es, aus dem Material übergeordnete Themen zu extrahieren, die zentrale Anforderungen der Nutzenden widerspiegeln. Die Analyse wurde manuell in Microsoft Word durchgeführt und erfolgte induktiv. Zunächst analysierten wir die Transkripte unabhängig voneinander. Anschließend wurden die identifizierten Codes und Themen im Abgleich zusammengeführt. Bei abweichenden Codierungen wurden die Unterschiede besprochen und schließlich zu einer validen und konsistenten Kategorisierung zusammengefügt. Durch dieses Vorgehen wurde die Subjektivität einzelner Interpretationen reduziert und eine möglichst transparente Auswertung gewährleistet.

# Ergebnisse

## Qualitative Ergebnisse

Unsere qualitative Analyse besteht aus drei Einzelinterviews mit Studierenden der Medieninformatik an der Universität zu Lübeck. Hierbei wurden die Personen nach ihren Einschätzungen zu der Nutzung von KI bei der Erkennung von Misinformationen auf sozialen Medien befragt. Ziel war es, Anforderungen, Erwartungen und potenzielle Probleme solcher Systeme aus Sicht der Nutzenden zu identifizieren. Die zentralen Themen unserer Analyse sind in @tbl-zentrale_themen zusammengefasst und im Folgenden näher beschrieben.

Alle Befragten gaben an, bereits Erfahrungen im Umgang mit KI gesammelt zu haben und soziale Medien überwiegend für Kommunikations- und Unterhaltungszwecke zu nutzen. Zudem sehen sie KI grundsätzlich als ein geeignetes Werkzeug zur automatisierten Faktenprüfung. So äußerte eine Person, dass durch das Abgleichen der Informationen von der KI eine Art Peer Review geschaffen wird und schloss daraus, „dass KI für \[die Detektion von Misinformationen\] absolut geeignet ist“ (A3_3, Zeile 86).

Allerdings wurde mehrfach betont, dass Transparenz eine entscheidende Voraussetzung für das Vertrauen in die KI ist. So sollten Quellen offengelegt werden, „dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (A3_2, Zeile 99–100) „und vielleicht auch den Analyseweg“ (A3_1, Zeile 102-103). Den Nutzenden ist es demnach wichtig, dass im Zweifelsfall zusätzlich zur automatisierten Prüfung durch die KI eine manuelle Kontrolle möglich ist.

Im Hinblick auf die Effektivität der KI-gestützten Überprüfung wurde geäußert, dass die Kennzeichnung der geprüften Inhalte visuell hervorgehoben und schnell erkennbar sein sollte. Eine Person betonte, dass es „auf jeden Fall sehr sichtbar da sein \[sollte\]. Also das heißt, man soll nicht danach suchen müssen“ (A3_3, Z. 218–219). Besonders in sozialen Medien ist eine solche Sichtbarkeit entscheidend, da Nutzende Inhalte meist nur flüchtig wahrnehmen. Eine deutlich erkennbare Markierung kann in diesem Kontext dazu beitragen, die Wirksamkeit der KI-Überprüfung im Alltag zu erhöhen.

In den Interviews zeigte sich deutlich, dass die inhaltliche Richtigkeit der Überprüfungen gegenüber einer schnellen Verfügbarkeit priorisiert wurde. So urteilte eine der Interviewten: „das braucht ein bisschen, aber dafür ist es dann richtig eingeordnet“ (A3_1, Z. 179–180). Diese Einschätzung ist besonders relevant, da verschiedene KI-Modelle jeweils Kompromisse in einer der beiden Kategorien eingehen. Wie bereits in unserer Literaturanalyse dargelegt, erfordern Modelle mit besonders hoher Genauigkeit einen derart hohen Rechenaufwand, dass sie für eine Echtzeit-Anwendung ungeeignet sind [@gondwe_can_2025]. Das Ergebnis unserer Interviews ist jedoch, dass eine hohe inhaltliche Präzision gegenüber einer sofortigen Einordnung klar bevorzugt wird.

```{r tbl-zentrale_themen, results='asis'}
#| echo: false
library(kableExtra)

df <- data.frame(
  Thema = c("Potenzialbewertung von KI als Werkzeug", 
            "Transparenz durch Quellenangaben", 
            "Sichtbarkeit der Kennzeichnung", 
            "Priorisierung der inhaltlichen Korrektheit"),
  Definition = c("Einschätzung, dass KI bei der Identifikation von Misinformation unterstützen kann", 
                 "Forderung, dass die in der Überprüfung verwendeten Quellen offengelegt werden, um Transparenz zu gewährleisten", 
                 "Forderung, dass die Kennzeichnung der KI-Überprüfung visuell hervorgehoben wird, um Effektivität zu gewährleisen", 
                 "Bewertung, dass die inhaltliche Richtigkeit der Überprüfung wichtiger ist als deren schnelle Verfügbarkeit"),
  Zitat = c("„[…] Peer Review quasi dadurch zu schaffen […] also glaube ich schon sehr gut, dass KI für sowas absolut geeignet ist“ (A3_3, Zeile 83-86)", 
            "„Die Quellenangabe, dass man dann auch nachverfolgen kann, woher die Informationen kommen“ (A3_2, Zeile 99-100)", 
            "„Es sollte auf jeden Fall sehr sichtbar da sein. Also das heißt, man soll nicht danach suchen müssen“ (A3_3, Zeile 218-219)", 
            "„[…] dann speichert es falsch eingeordnet ab. Dann bringt einem das auch nichts, als wenn man sagt, das braucht ein bisschen, aber dafür ist es dann richtig eingeordnet und jeder kann es richtig abspeichern“ (A3_1, Zeile 177-180)")
)

kable(df, format = "latex", booktabs = TRUE, caption = "Zentrale Themen der qualitativen Analyse", longtable = TRUE, linesep = "\\addlinespace") %>%
  kable_styling(latex_options = c("hold_position")) %>%
  column_spec(1, width = "4cm") %>%
  column_spec(2, width = "5cm") %>%
  column_spec(3, width = "5cm")
```

# Diskussion

*Diskussion*

## Referenzen {.unnumbered}

::: {#refs}
:::
